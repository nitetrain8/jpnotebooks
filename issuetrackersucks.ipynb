{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_tmpl = \"https://issue.pbsbiotech.com/projects/%s/issues.csv?utf8=%%E2%%9C%%93&columns=all\"\n",
    "_p_urls = [\n",
    "    \"pbscustomer\", \"pbsdisposables\", \"pbsinstruments\", \n",
    "    \"magic-metals\", \"manufacturing\", \"pbssoftware\", \"swtesting\",\n",
    "    \"system-qualification-testing\"\n",
    "]\n",
    "project_urls = [url_tmpl % p for p in _p_urls]\n",
    "project_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Issuetracker API \n",
    "\n",
    "* TODO: Create IssueList class (?)\n",
    "* Parse Gantt HTML for class 'issue-subject' using style:width to determine hierarchy\n",
    "* Consider method of lazy evaluation of issue field generation by\n",
    "calling back to API to download project issues CSV, and update all issues\n",
    "in project. \n",
    "* Implement issue caching\n",
    "\n",
    "Issue():\n",
    "    * Add programmatic logging of all fields seen, ever.\n",
    "    * Map fields seen to types and conversion functions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import urllib\n",
    "import pyquery\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import dateutil.parser\n",
    "import lxml\n",
    "\n",
    "uj = urllib.parse.urljoin\n",
    "_sp_re = re.compile(r\"(\\d*?) (subproject)?(s{0,1})\")\n",
    "_name2id_re = re.compile(r\"(.*?)\\s*?#(\\d*)$\")\n",
    "\n",
    "class IssuetrackerAPI():\n",
    "    _login_url = \"/login\"\n",
    "    _proj_issues_url = \"/projects/%s/issues\"\n",
    "    _issues_url = \"/issues\"\n",
    "    _proj_url = \"/projects\"\n",
    "    \n",
    "    def __init__(self, base_url, username=None, pw=None):\n",
    "        r = urllib.parse.urlparse(base_url)\n",
    "        if not r.scheme and not r.netloc:\n",
    "            base_url = urllib.parse.urlunparse((\"https\", r.path, \"\", r.params, r.query, r.fragment))\n",
    "        self._base_url = base_url\n",
    "        self._sess = requests.Session()\n",
    "        self._headers = {}\n",
    "        \n",
    "        if username is None or pw is None:\n",
    "            raise ValueError(\"Must have valid username and password.\")\n",
    "        \n",
    "        self._username = username\n",
    "        self._password = pw\n",
    "        self._auth = (username, pw)\n",
    "        \n",
    "        self._cache = {}\n",
    "        \n",
    "    @property\n",
    "    def issues(self):\n",
    "        raise NotImplemented\n",
    "        \n",
    "    @property\n",
    "    def projects(self):\n",
    "        pj = self._cache.get(\"projects\")\n",
    "        if not pj:\n",
    "            pj = self.download_projects()\n",
    "            self._cache['projects'] = pj\n",
    "        return pj\n",
    "            \n",
    "    def login(self):\n",
    "        r1 = self._sess.get(self._base_url)\n",
    "        r1.raise_for_status()\n",
    "        q = pyquery.PyQuery(r1.content)\n",
    "        data = {}\n",
    "        for td in q(\"#login-form :input\"):\n",
    "            at = td.attrib\n",
    "            if 'name' in at:\n",
    "                k = at['name']\n",
    "                v = at.get('value', \"\")\n",
    "                data[k] = v\n",
    "                \n",
    "        data['username'] = self._username\n",
    "        data['password'] = self._password\n",
    "        \n",
    "        body = urllib.parse.urlencode(data)\n",
    "        r2 = self._sess.post(uj(self._base_url, self._login_url), body)\n",
    "        r2.raise_for_status()\n",
    "        if not pyquery.PyQuery(r2.content)(\"#loggedas\"):\n",
    "            raise ValueError(\"Invalid Username or Password\")\n",
    "        return r2\n",
    "        \n",
    "    def download_project_issues_csv(self, project, utf8=True, columns='all'):\n",
    "        r = self._download_project_csv(project, utf8, columns)\n",
    "        return self._parse_proj_csv(r.content)\n",
    "    \n",
    "    def _download_project_csv(self, project, utf8, columns):\n",
    "        if utf8:\n",
    "            utf8 = \"%E2%9C%93\"\n",
    "        else:\n",
    "            utf8 = \"\"\n",
    "        url_end = \".csv?utf8=%s&columns=%s\" \n",
    "        url = (self._proj_issues_url + url_end) % (project, utf8, columns)\n",
    "        url = uj(self._base_url, url)\n",
    "        r = self._sess.get(url)\n",
    "        r.raise_for_status()\n",
    "        return r\n",
    "    \n",
    "    def download_issue_pdf(self, id):\n",
    "        href = self._issues_url + \"/\" + str(id)\n",
    "        return self.download_issue_pdf2(href)\n",
    "\n",
    "    def download_issue_pdf2(self, href):\n",
    "        \"\"\" Sometimes it is more convenient to access issue by provided \n",
    "        href. \"\"\"\n",
    "        type = \".pdf\"\n",
    "        url = uj(self._base_url, href + type)\n",
    "        r = self._sess.get(url)\n",
    "        r.raise_for_status()\n",
    "        return r.content\n",
    "        \n",
    "    def _parse_proj_csv(self, csv, encoding='utf-8'):\n",
    "        if not isinstance(csv, str):\n",
    "            csv = csv.decode(encoding)\n",
    "        sl = csv.splitlines()\n",
    "        sl[0] = sl[0].lower().replace('\"', \"\")\n",
    "        lines = [l.split(\",\") for l in sl]\n",
    "        issues = OrderedDict()\n",
    "        for i, l in enumerate(lines[1:], 1):\n",
    "            issue = _Issue(line=sl[i], api=self)\n",
    "            for key, val in zip(lines[0], l):\n",
    "                issue[key] = val.strip('\"') or \"<n/a>\"\n",
    "            issue['#'] = int(issue['#'])\n",
    "            issues[issue['#']] = issue\n",
    "        return issues\n",
    "    \n",
    "#     def download_projects(self):\n",
    "#         url = uj(self._base_url, self._proj_url)\n",
    "#         r = self._sess.get(url)\n",
    "#         r.raise_for_status()\n",
    "#         c = r.content\n",
    "#         q = pyquery.PyQuery(c)\n",
    "#         q2 = q(\"#projects-index > [class='projects root']\")\n",
    "#         projects = _Project(self, \"All\", \"\")\n",
    "#         for e in q2.children(\".root\"):\n",
    "#             proj_ele = pyquery.PyQuery(e).children(\".root > a\")[0]\n",
    "#             pt = proj_ele.text\n",
    "#             phref = proj_ele.attrib['href'].split(\"/\")[-1]\n",
    "#             proj = projects.add(pt, phref)\n",
    "#             q4 = pyquery.PyQuery(e).children(\"[class='more collapsed']\")\n",
    "#             if len(q4) and _sp_re.match(q4[0].text):\n",
    "#                 q3 = pyquery.PyQuery(e)(\"[class='projects ']\")\n",
    "#                 for e2 in q3(\".child > .child > a\"):\n",
    "#                     proj.add(e2.text, e2.attrib['href'].split(\"/\")[-1])\n",
    "#         return projects\n",
    "\n",
    "    def download_projects(self):\n",
    "        url = uj(self._base_url, self._proj_url + \".xml\")\n",
    "        r = self._sess.get(url, auth=self._auth)\n",
    "        r.raise_for_status()\n",
    "        xml = lxml.etree.XML(r.content)\n",
    "        projects = {}\n",
    "        for proj in xml.findall(\"project\"):\n",
    "            p = Project.from_element(self, proj)\n",
    "            projects[p.name] = p\n",
    "        \n",
    "        # Second pass, process project subtasks\n",
    "        for p in projects.values():\n",
    "            if p.parent is not None:\n",
    "                parent = projects[p.parent['name']]\n",
    "                parent.add_subproject(p)\n",
    "        return projects\n",
    "    \n",
    "    def _download_gantt_raw(self, project):\n",
    "        url = (self._proj_issues_url % project) + \"/gantt\"\n",
    "        url = uj(self._base_url, url)\n",
    "        r1 = self._sess.get(url)\n",
    "        r1.raise_for_status()\n",
    "        return r1.content\n",
    "\n",
    "    def download_gantt(self, project):\n",
    "        c = _download_gantt_raw(self, project)\n",
    "        q = pyquery.PyQuery(c)\n",
    "        q2 = q(\".gantt_subjects\")\n",
    "        issues = []\n",
    "        for el in q2.children(\".issue-subject\"):\n",
    "            title = el.attrib['title']\n",
    "            e2=pyquery.PyQuery(el).children(\"span > a\")[0]\n",
    "            tracker, id = _name2id_re.match(e2.text).groups()\n",
    "            href = e2.attrib['href']\n",
    "            i = _Issue(api=self)\n",
    "            i.href = href\n",
    "            i.title = title\n",
    "            i.id = int(id)\n",
    "            i.tracker = tracker\n",
    "            issues.append(i)\n",
    "        return issues\n",
    "    \n",
    "    def _download_project_issues_iter(self, ops, limit, offset):\n",
    "        ops['limit'] = limit\n",
    "        ops['offset'] = offset\n",
    "        url = uj(self._base_url, self._issues_url + \".json\")\n",
    "        url += \"?\" + urllib.parse.urlencode(ops)\n",
    "        r = self._sess.get(url, auth=self._auth)\n",
    "        r.raise_for_status()\n",
    "        return r\n",
    "\n",
    "    def download_issues(self, project_id=None, created_on=None, modified_on=None):\n",
    "        ops = {}\n",
    "        if project_id:\n",
    "            if isinstance(project_id, str):\n",
    "                projects = self.projects\n",
    "                for p in projects.values():\n",
    "                    if p.name == project_id or p.identifier == project_id:\n",
    "                        break\n",
    "                else:\n",
    "                    raise ValueError(\"Unable to find project %r\" % project_id)\n",
    "                project_id = p.id\n",
    "            ops['project_id'] = project_id\n",
    "            \n",
    "        # Unfortunately the api for querying dates and ranges is \n",
    "        # quite awkward to translate into a sensible python api\n",
    "        \n",
    "        if created_on:\n",
    "            if not isinstance(created_on, str):\n",
    "                raise TypeError(\"Argument created_on must be type str- try .isoformat() (got type %r)\" % created_on)\n",
    "            ops['created_on'] = created_on\n",
    "            \n",
    "        if modified_on:\n",
    "            if not isinstance(modified_on, str):\n",
    "                raise TypeError(\"Argument created_on must be type str- try .isoformat() (got type %r)\" % modified_on)\n",
    "            ops['modified_on'] = modified_on\n",
    "            \n",
    "        yield from self._download_issues(ops)\n",
    "            \n",
    "\n",
    "    def _download_issues(self, ops):\n",
    "        offset = 0\n",
    "        limit = 100\n",
    "        limit = min(max(limit, 0), 100)\n",
    "        total_count = 0\n",
    "        while True:\n",
    "\n",
    "            r = self._download_project_issues_iter(ops, limit, offset)\n",
    "            d = json.loads(r.content.decode())\n",
    "            issues = d['issues']\n",
    "\n",
    "            if not issues:\n",
    "                break\n",
    "\n",
    "            yield from self._parse_issues(issues)\n",
    "\n",
    "            total_count = int(d.get('total_count',0))\n",
    "            offset += len(issues)\n",
    "            print(\"Downloading issues: %d/%d\" % (offset, total_count))\n",
    "            if offset >= total_count:\n",
    "                break\n",
    "\n",
    "    def _parse_issues(self, issues):\n",
    "        rv = {}\n",
    "        for i in issues:\n",
    "            yield Issue.from_json(self, **i)\n",
    "    \n",
    "\n",
    "def _parse_custom_fields(e):\n",
    "    rv = {}\n",
    "    for cf in e.findall(\"custom_field\"):\n",
    "        cfd = {}\n",
    "        cfd.update(cf.attrib)\n",
    "        v = cf.find(\"value\")\n",
    "        if v is None or v.text == 'blank':\n",
    "            val = None\n",
    "        else:\n",
    "            val = v.text\n",
    "        cfd['value'] = val\n",
    "        rv[cfd['name']] = cfd\n",
    "    return rv\n",
    "\n",
    "def _parse_datetime(e):\n",
    "    return dateutil.parser.parse(e.text)\n",
    "\n",
    "def _parse_int(e):\n",
    "    return int(e.text)\n",
    "\n",
    "def _parse_bool(e):\n",
    "    t = e.text.lower()\n",
    "    if t == 'false':\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def _parse_parent(e):\n",
    "    return {k:v for k,v in e.attrib.items()}\n",
    "\n",
    "\n",
    "class Project():\n",
    "    def __init__(self, api, id=0, name=\"\", identifier=\"\", description=\"\", parent=None, status=None, \n",
    "                 is_public=False, custom_fields=None, created_on=None, updated_on=None):\n",
    "        self._api = api\n",
    "        self.name = name\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.identifier = identifier\n",
    "        self.description = description\n",
    "        self.parent = parent\n",
    "        self.status = status\n",
    "        self.is_public = is_public\n",
    "        self.custom_fields = custom_fields\n",
    "        self.created_on = created_on\n",
    "        self.updated_on = updated_on\n",
    "        self._subprojects = []\n",
    "        \n",
    "        \n",
    "    def add_subproject(self, sp):\n",
    "        sp.parent = self\n",
    "        if sp not in self._subprojects:\n",
    "            self._subprojects.append(sp)\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return \"_Project(%s)\" % ', '.join(\"%s=%r\" % (k[0], getattr(self, k[0])) for k in self._proj_parse_table)\n",
    "    \n",
    "    def download_issues(self, utf8=True, columns='all'):\n",
    "        return self._api.download_project_issues(self.identifier, utf8, columns)\n",
    "    \n",
    "    def download_gantt(self):\n",
    "        return self._api.download_gantt(self.identifier)\n",
    "        \n",
    "    _proj_parse_table = [\n",
    "        # e.tag attr parse function\n",
    "        (\"id\", \"id\", _parse_int),\n",
    "        (\"name\", \"name\", None),\n",
    "        (\"identifier\", \"identifier\", None),\n",
    "        (\"description\", \"description\", None),\n",
    "        (\"parent\", \"parent\", _parse_parent),\n",
    "        (\"status\", \"status\", _parse_int),\n",
    "        (\"is_public\", \"is_public\", _parse_bool),\n",
    "        (\"custom_fields\", \"custom_fields\", _parse_custom_fields),\n",
    "        (\"created_on\", \"created_on\", _parse_datetime),\n",
    "        (\"updated_on\", \"updated_on\", _parse_datetime),\n",
    "    ]\n",
    "        \n",
    "    @classmethod\n",
    "    def from_element(cls, api, e):\n",
    "        kw = {}\n",
    "        for tag, k, func in cls._proj_parse_table:\n",
    "            el = e.find(tag)\n",
    "            if el is None:\n",
    "                continue\n",
    "            if func:\n",
    "                v = func(el)\n",
    "            else:\n",
    "                v = el.text\n",
    "            if v is not None:\n",
    "                kw[k] = v\n",
    "        if not kw and e.tag != 'project':\n",
    "            raise ValueError(\"Failed to parse element: element should be <project> element.\")\n",
    "        return cls(api, **kw)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = IssuetrackerAPI(\"issue.pbsbiotech.com\", 'nstarkweather', 'kookychemist')\n",
    "r2=i.login()\n",
    "try:\n",
    "    jd\n",
    "except NameError:\n",
    "    jd = {'issue':{}}\n",
    "#issues = i.download_project_issues('pbssoftware')\n",
    "#iss = next(_ for _ in issues.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "jd2 = json.loads(i._sess.get(\"https://issue.pbsbiotech.com/issues/2206.json\", auth=i._auth).content.decode())\n",
    "jd['issue'].update(jd2['issue'])\n",
    "for f in jd2['issue']['custom_fields']:\n",
    "    jd['issue'][f['name']] = f['value']\n",
    "#print(jd2['issue']['custom_fields'])\n",
    "#print(json.dumps(jd, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#raw=i._download_project_csv('pbssoftware', True, 'all')\n",
    "r = raw.content.decode().splitlines()[0].split(\",\")\n",
    "r = [_.replace('\"', \"\") for _ in r]\n",
    "r[0] = 'id'\n",
    "r.sort(key=str.lower)\n",
    "r[0] = 'done_ratio'\n",
    "r.sort(key=str.lower)\n",
    "\n",
    "js = sorted(jd['issue'].keys(), key=lambda s: s.lower())\n",
    "from itertools import zip_longest\n",
    "print(\"   R               JS\")\n",
    "for a, b in zip_longest(r, js, fillvalue=\"\"):\n",
    "    print(\"%-30s %-30s\"%(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading issues: 31/31\n",
      "Issue #3270 2016-08-30 17:02:40+00:00 > 2016-08-10\n",
      "Issue #3269 2016-08-30 16:56:23+00:00 > 2016-08-10\n",
      "Issue #3268 2016-08-29 20:56:07+00:00 > 2016-08-10\n",
      "Issue #3267 2016-08-29 17:21:04+00:00 > 2016-08-10\n",
      "Issue #3266 2016-08-24 17:11:13+00:00 > 2016-08-10\n",
      "Issue #3264 2016-08-23 17:54:45+00:00 > 2016-08-10\n",
      "Issue #3261 2016-08-19 18:41:28+00:00 > 2016-08-10\n",
      "Issue #3260 2016-08-19 18:34:35+00:00 > 2016-08-10\n",
      "Issue #3259 2016-08-18 22:23:38+00:00 > 2016-08-10\n",
      "Issue #3258 2016-08-18 22:05:43+00:00 > 2016-08-10\n",
      "Issue #3255 2016-08-17 23:58:28+00:00 > 2016-08-10\n",
      "Issue #3254 2016-08-17 22:36:36+00:00 > 2016-08-10\n",
      "Issue #3253 2016-08-17 21:45:29+00:00 > 2016-08-10\n",
      "Issue #3252 2016-08-17 19:04:50+00:00 > 2016-08-10\n",
      "Issue #3251 2016-08-17 18:59:37+00:00 > 2016-08-10\n",
      "Issue #3250 2016-08-16 23:47:08+00:00 > 2016-08-10\n",
      "Issue #3249 2016-08-16 23:15:42+00:00 > 2016-08-10\n",
      "Issue #3248 2016-08-16 23:11:04+00:00 > 2016-08-10\n",
      "Issue #3247 2016-08-16 22:57:57+00:00 > 2016-08-10\n",
      "Issue #3246 2016-08-16 22:27:23+00:00 > 2016-08-10\n",
      "Issue #3245 2016-08-16 22:04:30+00:00 > 2016-08-10\n",
      "Issue #3244 2016-08-16 21:55:55+00:00 > 2016-08-10\n",
      "Issue #3243 2016-08-16 20:57:46+00:00 > 2016-08-10\n",
      "Issue #3242 2016-08-16 20:56:16+00:00 > 2016-08-10\n",
      "Issue #3241 2016-08-16 19:39:56+00:00 > 2016-08-10\n",
      "Issue #3240 2016-08-16 19:22:37+00:00 > 2016-08-10\n",
      "Issue #3239 2016-08-16 18:33:14+00:00 > 2016-08-10\n",
      "Issue #3238 2016-08-16 17:36:34+00:00 > 2016-08-10\n",
      "Issue #3237 2016-08-10 23:36:53+00:00 = 2016-08-10\n",
      "Issue #3236 2016-08-10 23:29:36+00:00 = 2016-08-10\n",
      "Issue #3235 2016-08-10 20:16:00+00:00 = 2016-08-10\n"
     ]
    }
   ],
   "source": [
    "d=i.download_issues('pbssoftware', \">=2016-08-10\")\n",
    "def iter5(ob):\n",
    "    rv=[];ap=rv.append\n",
    "    for _ in range(5):\n",
    "        ap(next(ob,None))\n",
    "    return rv\n",
    "import collections; exhaust = collections.deque(maxlen=0).extend\n",
    "l = list(d)\n",
    "import datetime\n",
    "d2 = datetime.datetime(2016, 8, 10).date()\n",
    "for item in l:\n",
    "    co = item.created_on.date()\n",
    "    mark = \"<\" if co < d2 else \">\" if co > d2 else \"=\"\n",
    "    print(\"Issue #%d\" % item.id, item.created_on, mark, d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Issue(author=User(name='James Small', id=42), custom_fields=[], sprint_milestone=ResourceWithID(name='Future Release', id=33), category=None, status=ResourceWithID(name='New', id=1), company=None, created_on=datetime.datetime(2016, 8, 30, 17, 2, 40, tzinfo=tzutc()), description='', subject='List all interlocks in Shell UI', done_ratio=None, crm_reply_token=None, updated_on=datetime.datetime(2016, 8, 30, 17, 2, 40, tzinfo=tzutc()), id=3270, project=_Project(id=5, name='Software', identifier='pbssoftware', description='This project collects all issues and features in regards to software', parent=None, status=1, is_public=False, custom_fields={'Customer Information': {'name': 'Customer Information', 'id': '2', 'value': None}}, created_on=datetime.datetime(2010, 10, 14, 10, 55, 55, tzinfo=tzutc()), updated_on=datetime.datetime(2010, 10, 14, 11, 7, 58, tzinfo=tzutc())), contact=None, priority=ResourceWithID(name='Normal', id=4), due_date=None, estimated_hours=None, tracker=ResourceWithID(name='Feature', id=2), parent=None, closed_on=None, start_date=datetime.datetime(2016, 8, 30, 0, 0), tracking_uri=None, assigned_to=User(name='Nathan Starkweather', id=39))"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0].description = \"\"\n",
    "l[0].custom_fields = []\n",
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _unrecognized_kw(kw):\n",
    "    return ValueError(\"Unrecognized keywords: %s\" % (', '.join(repr(s) for s in kw)))\n",
    "\n",
    "def _iss_parse_datetime(api, a, v):\n",
    "    return dateutil.parser.parse(v)\n",
    "\n",
    "def _iss_parse_int(api, a, v):\n",
    "    return int(v)\n",
    "\n",
    "def _iss_parse_usr(api, a, v):\n",
    "    name = v.pop('name')\n",
    "    id = v.pop('id')\n",
    "    if v:\n",
    "        raise _unrecognized_kw(v)\n",
    "    return User(api, name, id)\n",
    "\n",
    "def _iss_parse_resource(api, a, v):\n",
    "    name = v.pop('name')\n",
    "    id = v.pop('id')\n",
    "    value = v.pop('value', \"\")\n",
    "    if v:\n",
    "        raise _unrecognized_kw(v)\n",
    "    return ResourceWithID(api, name, id, value)\n",
    "\n",
    "def _iss_parse_project(api, a, v):\n",
    "    return api.projects[v['name']]\n",
    "\n",
    "def _parse_custom_fields(api, a, v):\n",
    "    fields = {}\n",
    "    for d in v:\n",
    "        name = d.pop('name')\n",
    "        id = d.pop('id')\n",
    "        val = d.pop('value', \"\")\n",
    "        if d:\n",
    "            raise _unrecognized_kw(d)\n",
    "        r = ResourceWithID(api, name, id, val)\n",
    "        fields[name] = val\n",
    "    return fields\n",
    "\n",
    "\n",
    "class ResourceWithID():\n",
    "    def __init__(self, api, name, id, value=\"\"):\n",
    "        self.api = api\n",
    "        self.name = name\n",
    "        self.id = id\n",
    "        self.value = value\n",
    "        \n",
    "    def __repr__(self):\n",
    "        n = self.__class__.__name__\n",
    "        args = ', '.join(\"%s=%r\" % (a, getattr(self, a)) for a in (\"name\", 'id'))\n",
    "        return \"%s(%s)\" % (n, args)\n",
    "\n",
    "\n",
    "class User(ResourceWithID):\n",
    "    def __init__(self, api, name, id):\n",
    "        super().__init__(api, name, id)\n",
    "        del self.value\n",
    "\n",
    "\n",
    "class Issue():\n",
    "    \n",
    "    _issue_parse_tbl = [\n",
    "        (\"author\", \"author\", _iss_parse_usr),\n",
    "        (\"custom_fields\", \"custom_fields\", _parse_custom_fields),\n",
    "        (\"fixed_version\", \"sprint_milestone\", _iss_parse_resource),  # oddly named. TODO double check this\n",
    "        (\"category\", \"category\", None),\n",
    "        (\"status\", \"status\", _iss_parse_resource),\n",
    "        (\"company\", \"company\", None),\n",
    "        (\"created_on\", \"created_on\", _iss_parse_datetime),\n",
    "        (\"description\", \"description\", None),\n",
    "        (\"subject\", \"subject\", None),\n",
    "        (\"done_ratio\", \"done_ratio\", None),\n",
    "        (\"crm_reply_token\", \"crm_reply_token\", None),\n",
    "        (\"updated_on\", \"updated_on\", _iss_parse_datetime),\n",
    "        (\"id\", \"id\", _iss_parse_int),\n",
    "        (\"project\", \"project\", _iss_parse_project),\n",
    "        (\"contact\", \"contact\", None),\n",
    "        (\"priority\", \"priority\", _iss_parse_resource),\n",
    "        (\"due_date\", \"due_date\", _iss_parse_datetime),\n",
    "        (\"estimated_hours\", \"estimated_hours\", None),\n",
    "        (\"tracker\", \"tracker\", _iss_parse_resource),\n",
    "        (\"parent\", \"parent\", None),\n",
    "        (\"closed_on\", \"closed_on\", _iss_parse_datetime),\n",
    "        (\"start_date\", \"start_date\", _iss_parse_datetime),\n",
    "        (\"tracking_uri\", \"tracking_uri\", None),\n",
    "        (\"assigned_to\", \"assigned_to\", _iss_parse_usr)\n",
    "    ]\n",
    "\n",
    "    def __init__(self, api, author=None, custom_fields=None, sprint_milestone=None, category=None, status=None, \n",
    "                  company=None, created_on=None, description=None, subject=None, done_ratio=None, crm_reply_token=None, \n",
    "                  updated_on=None, id=None, project=None, contact=None, priority=None, due_date=None, estimated_hours=None, \n",
    "                  tracker=None, parent=None, closed_on=None, start_date=None, tracking_uri=None, assigned_to=None):\n",
    "        \n",
    "        self._api = api\n",
    "        \n",
    "        self.author = author\n",
    "        self.custom_fields = custom_fields\n",
    "        self.sprint_milestone = sprint_milestone  \n",
    "        self.category = category\n",
    "        self.status = status\n",
    "        self.company = company\n",
    "        self.created_on = created_on\n",
    "        self.description = description\n",
    "        self.subject = subject\n",
    "        self.done_ratio = done_ratio\n",
    "        self.crm_reply_token = crm_reply_token\n",
    "        self.updated_on = updated_on\n",
    "        self.id = id\n",
    "        self.project = project\n",
    "        self.contact = contact\n",
    "        self.priority = priority\n",
    "        self.due_date = due_date\n",
    "        self.estimated_hours = estimated_hours\n",
    "        self.tracker = tracker\n",
    "        self.parent = parent\n",
    "        self.closed_on = closed_on\n",
    "        self.start_date = start_date\n",
    "        self.tracking_uri = tracking_uri\n",
    "        self.assigned_to = assigned_to\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, api, **kw):\n",
    "        dct = {}\n",
    "        absent = object()\n",
    "        for k, attr, func in cls._issue_parse_tbl:\n",
    "            v = kw.pop(k, absent)\n",
    "            if v is absent or not v:\n",
    "                continue\n",
    "            if func:\n",
    "                v = func(api, attr, v)\n",
    "            dct[attr] = v\n",
    "        if kw:\n",
    "            raise _unrecognized_kw(kw)\n",
    "        return cls(api, **dct)\n",
    "\n",
    "    def pretty_print(self):\n",
    "        attrs = [t[1] for t in self._issue_parse_tbl]\n",
    "        args = \", \".join(\"%s=%r\" % (a, getattr(self, a)) for a in attrs)\n",
    "        if not args: args = '<empty>'\n",
    "        return \"Issue(%s)\" % args\n",
    "\n",
    "    def download(self, type='pdf'):\n",
    "        return self._api.download_issue_pdf(self.id)\n",
    "    \n",
    "    __str__ = __repr__ = pretty_print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading issues: 100/670\n",
      "Downloading issues: 200/670\n",
      "Downloading issues: 300/670\n",
      "Downloading issues: 400/670\n",
      "Downloading issues: 500/670\n",
      "Downloading issues: 600/670\n",
      "Downloading issues: 670/670\n",
      "Downloading multithreaded 20/109           "
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "def download_worker(url, q, user, pw):\n",
    "    i = IssuetrackerAPI(url, user, pw)\n",
    "    i.login()\n",
    "    while True:\n",
    "        iss = q.get(True)\n",
    "        if iss is None:\n",
    "            return\n",
    "        pdf = iss.download()\n",
    "        write(iss.id, pdf)\n",
    "        \n",
    "def write(id, pdf):\n",
    "    fn = \"pdfs2/%d.pdf\" % id\n",
    "    with open(fn, 'wb') as f:\n",
    "        f.write(pdf)\n",
    "        \n",
    "def download_issues(issues, filter_cb=lambda i: True):\n",
    "    issues = [i for i in issues if filter_cb(i)]\n",
    "    threads = []\n",
    "    url = issues[0]._api._base_url.replace(\"https://\", \"\")  # todo urllib.parse.urlparse().domain or w/e\n",
    "    user = issues[0]._api._username\n",
    "    pw = issues[0]._api._password\n",
    "    q = queue.Queue()\n",
    "    threads = []\n",
    "    for i in range(8):\n",
    "        t = threading.Thread(None, download_worker, args=(url, q, user, pw), daemon=True)\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.start()\n",
    "    for i in issues:\n",
    "        q.put(i)\n",
    "    for i in range(8):\n",
    "        q.put(None)\n",
    "    while True:\n",
    "        if not any(t.is_alive() for t in threads):\n",
    "            break\n",
    "        print(\"\\rDownloading multithreaded %d/%d           \" % (len(issues) - (q.qsize()), len(issues)), end=\"\")\n",
    "        import time\n",
    "        time.sleep(.5)\n",
    "    print(\"Done\")\n",
    "        \n",
    "\n",
    "i = IssuetrackerAPI('issue.pbsbiotech.com', 'nstarkweather', 'kookychemist')\n",
    "i.login()\n",
    "issues=i.download_issues('pbssoftware', modified_on=\">=2016-6-01\")\n",
    "import os, shutil\n",
    "shutil.rmtree(\"pdfs2\")\n",
    "os.makedirs(\"pdfs2\", exist_ok=True)\n",
    "\n",
    "def filter_cb(iss):\n",
    "    return iss.sprint_milestone.name == \"3.0\" and iss.tracker.name == \"Specification\"\n",
    "\n",
    "download_issues(issues, filter_cb)\n",
    "\n",
    "# for n, iss in enumerate(issues, 1):\n",
    "#     fn = \"pdfs/%d.pdf\" % iss.id\n",
    "#     pdf = iss.download()\n",
    "#     print(\"\\rDownloading: %d / %d       \" % (n, len(issues)), end=\"\")\n",
    "#     with open(fn, 'wb') as f:\n",
    "#         f.write(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "is_alive() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-457-32795a2f17f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: is_alive() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "threading.Thread.is_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import queue\n",
    "queue.Queue().qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
