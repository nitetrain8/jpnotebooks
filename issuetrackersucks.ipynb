{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_tmpl = \"https://issue.pbsbiotech.com/projects/%s/issues.csv?utf8=%%E2%%9C%%93&columns=all\"\n",
    "_p_urls = [\n",
    "    \"pbscustomer\", \"pbsdisposables\", \"pbsinstruments\", \n",
    "    \"magic-metals\", \"manufacturing\", \"pbssoftware\", \"swtesting\",\n",
    "    \"system-qualification-testing\"\n",
    "]\n",
    "project_urls = [url_tmpl % p for p in _p_urls]\n",
    "project_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Issuetracker API \n",
    "\n",
    "* TODO: Create IssueList class (?)\n",
    "* Parse Gantt HTML for class 'issue-subject' using style:width to determine hierarchy\n",
    "* Consider method of lazy evaluation of issue field generation by\n",
    "calling back to API to download project issues CSV, and update all issues\n",
    "in project. \n",
    "* Implement issue caching\n",
    "\n",
    "Issue():\n",
    "    * Add programmatic logging of all fields seen, ever.\n",
    "    * Map fields seen to types and conversion functions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import urllib\n",
    "import pyquery\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import dateutil.parser\n",
    "import lxml\n",
    "\n",
    "uj = urllib.parse.urljoin\n",
    "_sp_re = re.compile(r\"(\\d*?) (subproject)?(s{0,1})\")\n",
    "_name2id_re = re.compile(r\"(.*?)\\s*?#(\\d*)$\")\n",
    "\n",
    "class IssuetrackerAPI():\n",
    "    _login_url = \"/login\"\n",
    "    _proj_issues_url = \"/projects/%s/issues\"\n",
    "    _issues_url = \"/issues\"\n",
    "    _proj_url = \"/projects\"\n",
    "    \n",
    "    def __init__(self, base_url, username=None, pw=None):\n",
    "        r = urllib.parse.urlparse(base_url)\n",
    "        if not r.scheme and not r.netloc:\n",
    "            base_url = urllib.parse.urlunparse((\"https\", r.path, \"\", r.params, r.query, r.fragment))\n",
    "        self._base_url = base_url\n",
    "        self._sess = requests.Session()\n",
    "        self._headers = {}\n",
    "        \n",
    "        if username is None or pw is None:\n",
    "            raise ValueError(\"Must have valid username and password.\")\n",
    "        \n",
    "        self._username = username\n",
    "        self._password = pw\n",
    "        self._auth = (username, pw)\n",
    "        \n",
    "        self._cache = {}\n",
    "        \n",
    "    @property\n",
    "    def issues(self):\n",
    "        raise NotImplemented\n",
    "        \n",
    "    @property\n",
    "    def projects(self):\n",
    "        pj = self._cache.get(\"projects\")\n",
    "        if not pj:\n",
    "            pj = self.down_projects()\n",
    "            self._cache['projects'] = pj\n",
    "        return pj\n",
    "            \n",
    "    def login(self):\n",
    "\n",
    "        r1 = self._sess.get(self._base_url)\n",
    "        r1.raise_for_status()\n",
    "        q = pyquery.PyQuery(r1.content)\n",
    "        data = {}\n",
    "        for td in q(\"#login-form :input\"):\n",
    "            at = td.attrib\n",
    "            if 'name' in at:\n",
    "                k = at['name']\n",
    "                v = at.get('value', \"\")\n",
    "                data[k] = v\n",
    "                \n",
    "        data['username'] = self._username\n",
    "        data['password'] = self._password\n",
    "        \n",
    "        body = urllib.parse.urlencode(data)\n",
    "        r2 = self._sess.post(uj(self._base_url, self._login_url), body)\n",
    "        r2.raise_for_status()\n",
    "        if not pyquery.PyQuery(r2.content)(\"#loggedas\"):\n",
    "            raise ValueError(\"Invalid Username or Password\")\n",
    "        return r2\n",
    "        \n",
    "    def download_project_issues(self, project, utf8=True, columns='all'):\n",
    "        r = self._download_project_csv(project, utf8, columns)\n",
    "        return self._parse_proj_csv(r.content)\n",
    "    \n",
    "    def _download_project_csv(self, project, utf8, columns):\n",
    "        if utf8:\n",
    "            utf8 = \"%E2%9C%93\"\n",
    "        else:\n",
    "            utf8 = \"\"\n",
    "        url_end = \".csv?utf8=%s&columns=%s\" \n",
    "        url = (self._proj_issues_url + url_end) % (project, utf8, columns)\n",
    "        url = uj(self._base_url, url)\n",
    "        r = self._sess.get(url)\n",
    "        r.raise_for_status()\n",
    "        return r\n",
    "    \n",
    "    def download_issue(self, id, type='pdf'):\n",
    "        href = self._issues_url + \"/\" + str(id)\n",
    "        return self.download_issue2(href, type)\n",
    "\n",
    "    \n",
    "    def download_issue2(self, href, type='pdf'):\n",
    "        \"\"\" Sometimes it is more convenient to access issue by provided \n",
    "        href. \"\"\"\n",
    "        assert type in ('pdf', '.pdf'), \"Non-pdf download not supported\"\n",
    "        if type[0] != \".\":\n",
    "            type = \".\" + type\n",
    "        url = uj(self._base_url, name + type)\n",
    "        r = self._sess.get(url)\n",
    "        r.raise_for_status()\n",
    "        return r.content\n",
    "        \n",
    "    def _parse_proj_csv(self, csv, encoding='utf-8'):\n",
    "        if not isinstance(csv, str):\n",
    "            csv = csv.decode(encoding)\n",
    "        sl = csv.splitlines()\n",
    "        sl[0] = sl[0].lower().replace('\"', \"\")\n",
    "        lines = [l.split(\",\") for l in sl]\n",
    "        issues = OrderedDict()\n",
    "        for i, l in enumerate(lines[1:], 1):\n",
    "            issue = _Issue(line=sl[i], api=self)\n",
    "            for key, val in zip(lines[0], l):\n",
    "                issue[key] = val.strip('\"') or \"<n/a>\"\n",
    "            issue['#'] = int(issue['#'])\n",
    "            issues[issue['#']] = issue\n",
    "        return issues\n",
    "    \n",
    "#     def download_projects(self):\n",
    "#         url = uj(self._base_url, self._proj_url)\n",
    "#         r = self._sess.get(url)\n",
    "#         r.raise_for_status()\n",
    "#         c = r.content\n",
    "#         q = pyquery.PyQuery(c)\n",
    "#         q2 = q(\"#projects-index > [class='projects root']\")\n",
    "#         projects = _Project(self, \"All\", \"\")\n",
    "#         for e in q2.children(\".root\"):\n",
    "#             proj_ele = pyquery.PyQuery(e).children(\".root > a\")[0]\n",
    "#             pt = proj_ele.text\n",
    "#             phref = proj_ele.attrib['href'].split(\"/\")[-1]\n",
    "#             proj = projects.add(pt, phref)\n",
    "#             q4 = pyquery.PyQuery(e).children(\"[class='more collapsed']\")\n",
    "#             if len(q4) and _sp_re.match(q4[0].text):\n",
    "#                 q3 = pyquery.PyQuery(e)(\"[class='projects ']\")\n",
    "#                 for e2 in q3(\".child > .child > a\"):\n",
    "#                     proj.add(e2.text, e2.attrib['href'].split(\"/\")[-1])\n",
    "#         return projects\n",
    "\n",
    "    def download_projects(self):\n",
    "        url = uj(self._base_url, self._proj_url + \".xml\")\n",
    "        r = self._sess.get(url, auth=self._auth)\n",
    "        r.raise_for_status()\n",
    "        xml = lxml.etree.XML(r.content)\n",
    "        projects = {}\n",
    "        for proj in xml.findall(\"project\"):\n",
    "            p = Project.from_element(self, proj)\n",
    "            projects[p.name] = p\n",
    "        \n",
    "        # Second pass, process project subtasks\n",
    "        for p in projects.values():\n",
    "            if p.parent is not None:\n",
    "                parent = projects[p.parent['name']]\n",
    "                parent.add_subproject(p)\n",
    "        return projects\n",
    "    \n",
    "    def _download_gantt_raw(self, project):\n",
    "        url = (self._proj_issues_url % project) + \"/gantt\"\n",
    "        url = uj(self._base_url, url)\n",
    "        r1 = self._sess.get(url)\n",
    "        r1.raise_for_status()\n",
    "        return r1.content\n",
    "\n",
    "    def download_gantt(self, project):\n",
    "        c = _download_gantt_raw(self, project)\n",
    "        q = pyquery.PyQuery(c)\n",
    "        q2 = q(\".gantt_subjects\")\n",
    "        issues = []\n",
    "        for el in q2.children(\".issue-subject\"):\n",
    "            title = el.attrib['title']\n",
    "            e2=pyquery.PyQuery(el).children(\"span > a\")[0]\n",
    "            tracker, id = _name2id_re.match(e2.text).groups()\n",
    "            href = e2.attrib['href']\n",
    "            i = _Issue(api=self)\n",
    "            i.href = href\n",
    "            i.title = title\n",
    "            i.id = int(id)\n",
    "            i.tracker = tracker\n",
    "            issues.append(i)\n",
    "        return issues\n",
    "    \n",
    "\n",
    "def _parse_custom_fields(e):\n",
    "    rv = {}\n",
    "    for cf in e.findall(\"custom_field\"):\n",
    "        cfd = {}\n",
    "        cfd.update(cf.attrib)\n",
    "        v = cf.find(\"value\")\n",
    "        if v is None or v.text == 'blank':\n",
    "            val = None\n",
    "        else:\n",
    "            val = v.text\n",
    "        cfd['value'] = val\n",
    "        rv[cfd['name']] = cfd\n",
    "    return rv\n",
    "\n",
    "def _parse_datetime(e):\n",
    "    return dateutil.parser.parse(e.text)\n",
    "\n",
    "def _parse_int(e):\n",
    "    return int(e.text)\n",
    "\n",
    "def _parse_bool(e):\n",
    "    t = e.text.lower()\n",
    "    if t == 'false':\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def _parse_parent(e):\n",
    "    return {k:v for k,v in e.attrib.items()}\n",
    "\n",
    "\n",
    "class Project():\n",
    "    def __init__(self, api, id=0, name=\"\", identifier=\"\", description=\"\", parent=None, status=None, \n",
    "                 is_public=False, custom_fields=None, created_on=None, updated_on=None):\n",
    "        self._api = api\n",
    "        self.name = name\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.identifier = identifier\n",
    "        self.description = description\n",
    "        self.parent = parent\n",
    "        self.status = status\n",
    "        self.is_public = is_public\n",
    "        self.custom_fields = custom_fields\n",
    "        self.created_on = created_on\n",
    "        self.updated_on = updated_on\n",
    "        self._subprojects = []\n",
    "        \n",
    "    def add_subproject(self, sp):\n",
    "        sp.parent = self\n",
    "        if sp not in self._subprojects:\n",
    "            self._subprojects.append(sp)\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return \"_Project(%s)\" % ', '.join(\"%s=%r\" % (k[0], getattr(self, k[0])) for k in self._proj_parse_table)\n",
    "    \n",
    "    def download_issues(self, utf8=True, columns='all'):\n",
    "        return self._api.download_project_issues(self.identifier, utf8, columns)\n",
    "    \n",
    "    def download_gantt(self):\n",
    "        return self._api.download_gantt(self.identifier)\n",
    "        \n",
    "    _proj_parse_table = [\n",
    "    # e.tag attr parse function\n",
    "    (\"id\", \"id\", _parse_int),\n",
    "    (\"name\", \"name\", None),\n",
    "    (\"identifier\", \"identifier\", None),\n",
    "    (\"description\", \"description\", None),\n",
    "    (\"parent\", \"parent\", _parse_parent),\n",
    "    (\"status\", \"status\", _parse_int),\n",
    "    (\"is_public\", \"is_public\", _parse_bool),\n",
    "    (\"custom_fields\", \"custom_fields\", _parse_custom_fields),\n",
    "    (\"created_on\", \"created_on\", _parse_datetime),\n",
    "    (\"updated_on\", \"updated_on\", _parse_datetime),\n",
    "]\n",
    "        \n",
    "    @classmethod\n",
    "    def from_element(cls, api, e):\n",
    "        kw = {}\n",
    "        for tag, k, func in cls._proj_parse_table:\n",
    "            el = e.find(tag)\n",
    "            if el is None:\n",
    "                continue\n",
    "            if func:\n",
    "                v = func(el)\n",
    "            else:\n",
    "                v = el.text\n",
    "            if v is not None:\n",
    "                kw[k] = v\n",
    "        if not kw and e.tag != 'project':\n",
    "            raise ValueError(\"Failed to parse element: element should be <project> element.\")\n",
    "        return cls(api, **kw)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = IssuetrackerAPI(\"issue.pbsbiotech.com\", 'nstarkweather', 'kookychemist')\n",
    "r2=i.login()\n",
    "try:\n",
    "    jd\n",
    "except NameError:\n",
    "    jd = {'issue':{}}\n",
    "#issues = i.download_project_issues('pbssoftware')\n",
    "#iss = next(_ for _ in issues.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "jd2 = json.loads(i._sess.get(\"https://issue.pbsbiotech.com/issues/2206.json\", auth=i._auth).content.decode())\n",
    "jd['issue'].update(jd2['issue'])\n",
    "for f in jd2['issue']['custom_fields']:\n",
    "    jd['issue'][f['name']] = f['value']\n",
    "#print(jd2['issue']['custom_fields'])\n",
    "#print(json.dumps(jd, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#raw=i._download_project_csv('pbssoftware', True, 'all')\n",
    "r = raw.content.decode().splitlines()[0].split(\",\")\n",
    "r = [_.replace('\"', \"\") for _ in r]\n",
    "r[0] = 'id'\n",
    "r.sort(key=str.lower)\n",
    "r[0] = 'done_ratio'\n",
    "r.sort(key=str.lower)\n",
    "\n",
    "js = sorted(jd['issue'].keys(), key=lambda s: s.lower())\n",
    "from itertools import zip_longest\n",
    "print(\"   R               JS\")\n",
    "for a, b in zip_longest(r, js, fillvalue=\"\"):\n",
    "    print(\"%-30s %-30s\"%(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_project_issues(self, project):\n",
    "    offset = 0\n",
    "    limit = 100\n",
    "    total_count = 0\n",
    "    rv1 = {}\n",
    "    while True:\n",
    "        ops = {\n",
    "            'limit': limit,\n",
    "            'project': project,\n",
    "            'offset': offset,\n",
    "        }\n",
    "\n",
    "        url = uj(self._base_url, self._issues_url + \".json\")\n",
    "        url += \"?\" + urllib.parse.urlencode(ops)\n",
    "        print(\"Downloading issues: %d/%d\" % (offset, total_count))\n",
    "        r = self._sess.get(url, auth=self._auth)\n",
    "        r.raise_for_status()\n",
    "        d = json.loads(r.content.decode())\n",
    "        issues = d['issues']\n",
    "        if not issues:\n",
    "            break\n",
    "        offset += len(issues)\n",
    "        for i in issues:\n",
    "            rv1[i['id']] = i\n",
    "        total_count = int(d.get('total_count',0))\n",
    "        \n",
    "        if offset > total_count:\n",
    "            break\n",
    "        break\n",
    "            \n",
    "    iss = _parse_issues(self, rv1.values())\n",
    "    print(len(iss), total_count)\n",
    "    return iss\n",
    "\n",
    "def _parse_issues(self, issues):\n",
    "    rv = {}\n",
    "    for i in issues:\n",
    "        print(i)\n",
    "        rv[int(i['id'])] = _Issue(self, **i)\n",
    "        break\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"offset\": 0,\n",
      "    \"limit\": 1,\n",
      "    \"issues\": [\n",
      "        {\n",
      "            \"author\": {\n",
      "                \"name\": \"James Small\",\n",
      "                \"id\": 42\n",
      "            },\n",
      "            \"updated_on\": \"2016-08-30T17:02:40Z\",\n",
      "            \"id\": 3270,\n",
      "            \"custom_fields\": [\n",
      "                {\n",
      "                    \"name\": \"Type of Request\",\n",
      "                    \"id\": 8,\n",
      "                    \"value\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Product Type\",\n",
      "                    \"id\": 4,\n",
      "                    \"value\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Serial No. Lot No.\",\n",
      "                    \"id\": 9,\n",
      "                    \"value\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Followup Actions\",\n",
      "                    \"id\": 6,\n",
      "                    \"value\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Return Material Authorization\",\n",
      "                    \"id\": 7,\n",
      "                    \"value\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Root Cause\",\n",
      "                    \"id\": 5,\n",
      "                    \"value\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Date Approved\",\n",
      "                    \"id\": 16,\n",
      "                    \"value\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"fixed_version\": {\n",
      "                \"name\": \"Future Release\",\n",
      "                \"id\": 33\n",
      "            },\n",
      "            \"status\": {\n",
      "                \"name\": \"New\",\n",
      "                \"id\": 1\n",
      "            },\n",
      "            \"created_on\": \"2016-08-30T17:02:40Z\",\n",
      "            \"description\": \"When the user clicks the \\\"About\\\" button they could be given a choice between Interlocks and Bioreactor Information, and Interlocks would show a list of all interlocks.  We should mock it up, and think about whether it would be genuinely helpful to users - if the Agitation is interlocked, do they check it in the Shell, in the Graphs, or Interlocks?\\r\\n\\r\\nThis is Nathan's idea so I'm assigning it to him, even though obviously it won't be him that ends up implementing it.\",\n",
      "            \"tracker\": {\n",
      "                \"name\": \"Feature\",\n",
      "                \"id\": 2\n",
      "            },\n",
      "            \"subject\": \"List all interlocks in Shell UI\",\n",
      "            \"start_date\": \"2016-08-30\",\n",
      "            \"project\": {\n",
      "                \"name\": \"Software\",\n",
      "                \"id\": 5\n",
      "            },\n",
      "            \"done_ratio\": 0,\n",
      "            \"priority\": {\n",
      "                \"name\": \"Normal\",\n",
      "                \"id\": 4\n",
      "            },\n",
      "            \"assigned_to\": {\n",
      "                \"name\": \"Nathan Starkweather\",\n",
      "                \"id\": 39\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"total_count\": 1140\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://issue.pbsbiotech.com/issues.json?limit=1?project=pbssoftware\"\n",
    "#c = i._sess.get(url, auth=i._auth).content\n",
    "d=json.loads(c.decode())#['issues'][0]\n",
    "s=json.dumps(d, indent=4)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading issues: 0/0\n",
      "{'author': {'name': 'James Small', 'id': 42}, 'updated_on': '2016-07-20T22:10:05Z', 'id': 3159, 'custom_fields': [{'name': 'Type of Request', 'id': 8, 'value': ''}, {'name': 'Product Type', 'id': 4, 'value': ''}, {'name': 'Serial No. Lot No.', 'id': 9, 'value': ''}, {'name': 'Followup Actions', 'id': 6, 'value': ''}, {'name': 'Return Material Authorization', 'id': 7, 'value': ''}, {'name': 'Root Cause', 'id': 5, 'value': ''}, {'name': 'Date Approved', 'id': 16, 'value': ''}], 'fixed_version': {'name': '3.0', 'id': 52}, 'status': {'name': 'Feedback', 'id': 4}, 'created_on': '2016-06-02T18:25:23Z', 'description': 'If the first batch is \"--\", the resulting array output will have end times before the start times.  The solution is to modify the SQL call for getting batches with name=\\'--\\' so it also does not get batches if their ID is 1.\\r\\n\\r\\nIf the first batch has a name, and the last batch has a name, the last batch\\'s end time will be \"--\" which is appropriate for the active DB, but for an archived DB it should report the start time of the next DB.  It will be better to get that information from the Database History file, rather than by sending an SQL call to the next DB, since it\\'s possible for the administrator of the customer\\'s bioreactor to delete databases.', 'tracker': {'name': 'Bug', 'id': 1}, 'subject': 'Get Batch Info from DB.vi potentially not correct for end of batch (discovered via unit testing)', 'start_date': '2016-06-02', 'project': {'name': 'Software', 'id': 5}, 'done_ratio': 0, 'priority': {'name': 'Normal', 'id': 4}, 'assigned_to': {'name': 'James Small', 'id': 42}}\n",
      "1 1140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[_Issue(author=None, updated_on=None, id=None, custom_fields=None, fixed_version=None, status=None, created_on=None, description=None, tracker=None, subject=None, start_date=None, project=None, done_ratio=None, priority=None, assigned_to=None)]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=download_project_issues(i, 'pbssoftware')\n",
    "list(d.values())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<module '__main__'> is a built-in class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-276-f9f43bfb335e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Issue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mc:\\program files\\python35\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mThe\u001b[0m \u001b[0msource\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     OSError is raised if the source code cannot be retrieved.\"\"\"\n\u001b[0;32m--> 944\u001b[0;31m     \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\program files\\python35\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetsourcelines\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    929\u001b[0m     raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m    930\u001b[0m     \u001b[0mobject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m     \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mismodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\program files\\python35\\lib\\inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    742\u001b[0m     is raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;31m# Invalidate cache if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\program files\\python35\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mno\u001b[0m \u001b[0mway\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0midentified\u001b[0m \u001b[0mto\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \"\"\"\n\u001b[0;32m--> 660\u001b[0;31m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m     \u001b[0mall_bytecode_suffixes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG_BYTECODE_SUFFIXES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0mall_bytecode_suffixes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZED_BYTECODE_SUFFIXES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\program files\\python35\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetfile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__file__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{!r} is a built-in class'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0mobject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <module '__main__'> is a built-in class"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
