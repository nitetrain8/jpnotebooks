{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import pickle\n",
    "import select\n",
    "import time\n",
    "import sys\n",
    "\n",
    "class ProxyError(OSError):\n",
    "    pass\n",
    "\n",
    "class ProxyTimeout(ProxyError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class BaseProtocol():\n",
    "    \"\"\" Mixin / common code for client & server side \n",
    "    protocols. \n",
    "    \"\"\"\n",
    "    SOCK_TIMEOUT = 30\n",
    "    RECV_TIMEOUT = 30\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._queue = {}\n",
    "        \n",
    "    def _makefiles(self):\n",
    "        self._wfile = self._sock.makefile(\"wb\")\n",
    "        self._rfile = self._sock.makefile(\"rb\")\n",
    "        self._sock.settimeout(self.SOCK_TIMEOUT)\n",
    "    \n",
    "    def close(self):\n",
    "        if self._wfile:\n",
    "            self._wfile.flush()\n",
    "            self._wfile.close()\n",
    "            self._wfile = None\n",
    "        if self._rfile:\n",
    "            self._rfile.close()\n",
    "            self._rfile = None\n",
    "            \n",
    "        self._sock.shutdown(socket.SDRW)\n",
    "        self._sock.close()\n",
    "        self._sock = None\n",
    "        \n",
    "    def send(self, data):\n",
    "        pickle.dump(data, self._wfile)\n",
    "        self._wfile.flush()\n",
    "        \n",
    "    def recv_one_msg(self):\n",
    "        r, w, x = select.select([self._sock], [], [], self.SOCK_TIMEOUT)\n",
    "        if r:\n",
    "            data = msg_load(self._rfile)\n",
    "            if data.msg == \"INTERNAL_ERROR\":\n",
    "                raise ProxyError(\"Internal error: '%s'\"%data)\n",
    "            return data\n",
    "        else:\n",
    "            raise ProxyTimeout(\"Socket read timeout\")\n",
    "        \n",
    "    def recv(self, id, timeout=-1, hard_timeout=None):\n",
    "        data = self._queue.pop(id, None)\n",
    "        if data is not None:\n",
    "            return data\n",
    "        \n",
    "        if timeout < 0:\n",
    "            timeout = self.RECV_TIMEOUT\n",
    "        \n",
    "        end = time.time() + timeout\n",
    "        \n",
    "        if hard_timeout is not None:\n",
    "            hard_end = max(end, time.time() + hard_timeout)\n",
    "        else:\n",
    "            hard_end = -1\n",
    "            \n",
    "        while True:\n",
    "            data = self.recv_one_msg()\n",
    "            if data.msg == \"HEARTBEAT\":\n",
    "                end = time.time() + timeout\n",
    "                if hard_end > 0 and end > hard_end:\n",
    "                    end = hard_end\n",
    "                continue\n",
    "                \n",
    "            if data.id != id:\n",
    "                self._queue[data.id] = data\n",
    "            else:\n",
    "                return data\n",
    "\n",
    "            if time.time() > end:\n",
    "                raise ProxyTimeout(\"Took too long to get confirmation for result\")\n",
    "\n",
    "        \n",
    "class MessageData():\n",
    "    def __init__(self):\n",
    "        self.id = None\n",
    "        self.msg = None\n",
    "        self.data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.tools.issuetracker import clientapi as capi\n",
    "import importlib\n",
    "capi = importlib.reload(capi)\n",
    "import threading\n",
    "import datetime\n",
    "\n",
    "class RedmineProxyError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "class RedmineCache():\n",
    "    def __init__(self):\n",
    "        self._cache = {}\n",
    "        self._updated = datetime.datetime(1970, 1, 1)\n",
    "        \n",
    "    def clear(self):\n",
    "        self._cache.clear()\n",
    "        \n",
    "    def lookup(self, id):\n",
    "        return self._cache[id]\n",
    "    \n",
    "    def get_all(self):\n",
    "        return self._cache.copy()\n",
    "    \n",
    "    def update(self, issues):\n",
    "        for iss in issues:\n",
    "            self._cache[iss.id] = iss\n",
    "        \n",
    "    @property\n",
    "    def last_update(self):\n",
    "        return self._updated\n",
    "    \n",
    "    def filter(self, pred):\n",
    "        out = {}\n",
    "        for iid, iss in self._cache.items():\n",
    "            try:\n",
    "                res = pred(iss)\n",
    "            except Exception:\n",
    "                raise ValueError(\"Exception occurred while performing filter with custom predicate\")\n",
    "            out[iid] = iss\n",
    "        return out\n",
    "    \n",
    "    def filter2(self, filters):\n",
    "        out = {}\n",
    "        for iid, iss in self._cache.items():\n",
    "            b = True\n",
    "            for v1, op, v2 in filters:\n",
    "                v1 = getattr(iss, v1)\n",
    "                if op == \"==\":\n",
    "                    b = b and v1 == v2\n",
    "                elif op == \"!=\":\n",
    "                    b = b and v1 != v2\n",
    "                elif op == \">=\":\n",
    "                    b = b and v1 >= v2\n",
    "                elif op == \"<=\":\n",
    "                    b = b and v1 <= v2\n",
    "                elif op == \">\":\n",
    "                    b = b and v1 > v2\n",
    "                elif op == \"<\":\n",
    "                    b = b and v1 < v2\n",
    "                else:\n",
    "                    raise ValueError(op)\n",
    "            if b:\n",
    "                out[iid] = iss\n",
    "        return out\n",
    "    \n",
    "    def set_update_time(self, time=None):\n",
    "        if time is None:\n",
    "            self._updated = datetime.datetime.now()\n",
    "        else:\n",
    "            assert isinstance(time, datetime.datetime)\n",
    "            self._updated = time\n",
    "        \n",
    "class _StopManagerThread(Exception):\n",
    "    pass\n",
    "\n",
    "class RedmineCacheManager(threading.Thread):\n",
    "    def __init__(self, update_interval=30):\n",
    "        self._api = None\n",
    "        self.lock = threading.Lock()  # just in case\n",
    "        self._stop = threading.Event()\n",
    "        self._cache = RedmineCache()\n",
    "        self._update_interval = update_interval # seconds\n",
    "        self._initialized = False\n",
    "        super().__init__(daemon=True)\n",
    "        \n",
    "    @property\n",
    "    def api(self):\n",
    "        if self._api is None:\n",
    "            self._api = capi.IssuetrackerAPI('issue.pbsbiotech.com', 'nstarkweather', 'kookychemist')\n",
    "        return self._api\n",
    "        \n",
    "    def run(self):\n",
    "        self._stop.clear()\n",
    "        try:\n",
    "            self._run()\n",
    "        except _StopManagerThread:\n",
    "            pass\n",
    "        \n",
    "    @property\n",
    "    def is_initialized(self):\n",
    "        return self._initialized\n",
    "        \n",
    "    def _run(self):\n",
    "        # on first iteration, populate cache with no delay\n",
    "        wait = 0\n",
    "        while True:\n",
    "            updated_on = \">=\" + self._cache.last_update.isoformat()\n",
    "            iiter = self._do_download(updated_on)\n",
    "            self._update_from_iter(iiter, 0)\n",
    "            self._cache.set_update_time()\n",
    "            \n",
    "            if self._stop.wait(self._update_interval):\n",
    "                raise _StopManagerThread()\n",
    "                \n",
    "            wait = 1\n",
    "            self._initialized = True\n",
    "            \n",
    "    def _update_from_iter(self, iiter, wait):\n",
    "        for issues in iiter:\n",
    "            self._cache.update(issues)\n",
    "            if self._stop.wait(wait):\n",
    "                raise _StopManagerThread()\n",
    "    \n",
    "    def _update_issues(self, issues):\n",
    "        with self.lock:\n",
    "            self._cache.update(issues)\n",
    "\n",
    "    def _do_download(self, updated_on):\n",
    "        try:\n",
    "            return self.api.download_issues2(modified_on=updated_on, status_id=\"*\")\n",
    "        except Exception as e:\n",
    "            raise RedmineProxyError(\"Error occurred collecting issues: \\\"%s\\\"\"%str(e))\n",
    "        \n",
    "    def stop(self):\n",
    "        self._stop.set()\n",
    "        \n",
    "    def get_all(self):\n",
    "        with self.lock:\n",
    "            return self._cache.get_all()\n",
    "    \n",
    "    def lookup(self, id):\n",
    "        with self.lock:\n",
    "            return self._cache.lookup(id)\n",
    "    \n",
    "    def filter(self, filters):\n",
    "        with self.lock:\n",
    "            return self._cache.filter2(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socketserver\n",
    "import http.server\n",
    "import urllib\n",
    "import base64\n",
    "import pickle\n",
    "import http\n",
    "import socket\n",
    "\n",
    "def encode(item):\n",
    "    b = pickle.dumps(item)\n",
    "    return base64.b64encode(b)\n",
    "\n",
    "def decode(string):\n",
    "    b = base64.b64decode(string)\n",
    "    return pickle.loads(b)\n",
    "\n",
    "def parse_params(params):\n",
    "    out = {}\n",
    "    for k, v in params.items():\n",
    "        if len(v) > 1:\n",
    "            raise ValueError(\"Too many arguments for %r: %r\" % (k, \", \".join(v)))\n",
    "        out[k] = v[0]\n",
    "    return out\n",
    "\n",
    "class RedmineRequestHandler(http.server.SimpleHTTPRequestHandler):\n",
    "    default_request_version = \"HTTP/1.1\"\n",
    "    \n",
    "    def do_GET(self):\n",
    "        res = urllib.parse.urlparse(self.path) \n",
    "        qs = res.query\n",
    "        params = urllib.parse.parse_qs(qs)\n",
    "        params = parse_params(params)\n",
    "        if res.path == \"/cache\":\n",
    "            if not self.server.manager.is_initialized:\n",
    "                return self.send_error(http.HTTPStatus.BAD_REQUEST, \"Service is still initializing\")\n",
    "            self._do_cache_request(params)\n",
    "        else:\n",
    "            self.send_error(http.HTTPStatus.BAD_REQUEST, \"Unknown path: %r\" % res.path)\n",
    "    \n",
    "    def _do_cache_request(self, params):\n",
    "    \n",
    "        if \"issues\" in params:\n",
    "            ireq = params[\"issues\"]\n",
    "            if ireq == 'all':\n",
    "                try:\n",
    "                    issues = self._do_request_all_issues()\n",
    "                except Exception as e:\n",
    "                    return self.send_error(http.HTTPStatus.INTERNAL_SERVER_ERROR, \"Big Oops: %r\"%str(e))\n",
    "            else:\n",
    "                l = ireq.split(\",\")\n",
    "                try:\n",
    "                    issues = list(map(int, l))\n",
    "                except ValueError:\n",
    "                    return self.send_error(\"invalid value for 'issues': %r\"%issues)\n",
    "                try:\n",
    "                    ret = [self.server.manager.lookup(i) for i in issues]\n",
    "                except KeyError as e:\n",
    "                    return self.send_error(http.HTTPStatus.NOT_FOUND, \"failed to find key: '%'\" % str(e))\n",
    "        elif \"filters\" in params:\n",
    "            filters = decode(params[\"filters\"])\n",
    "            try:\n",
    "                issues = self.server.manager.filter(filters)\n",
    "            except ValueError:\n",
    "                return self.send_error(http.HTTPStatus.BAD_REQUEST, \"bad filter string: %r\"%filters)\n",
    "        else:\n",
    "            return self.send_error(http.HTTPStatus.BAD_REQUEST, \"Unknown args: %r\" % params)\n",
    "            \n",
    "        rsp = encode(issues)\n",
    "        self.send_response(200)\n",
    "        self.send_header(\"Content-type\", \"text/plain\")\n",
    "        self.send_header(\"Content-Length\", str(len(rsp)))\n",
    "        self.end_headers()\n",
    "        self.wfile.write(rsp)\n",
    "        self.wfile.flush()\n",
    "            \n",
    "    def _do_request_all_issues(self):\n",
    "        return self.server.manager.get_all()\n",
    "\n",
    "class RedmineServer(socketserver.ThreadingTCPServer):\n",
    "    \n",
    "    def __init__(self, addr, manager=None):\n",
    "        self.manager = manager or RedmineCacheManager()\n",
    "        self.manager.start()\n",
    "        super().__init__(addr, RedmineRequestHandler)\n",
    "    \n",
    "    # from http.server.HTTPServer\n",
    "    def server_bind(self):\n",
    "        \"\"\"Override server_bind to store the server name.\"\"\"\n",
    "        socketserver.TCPServer.server_bind(self)\n",
    "        host, port = self.socket.getsockname()[:2]\n",
    "        self.server_name = socket.getfqdn(host)\n",
    "        self.server_port = port\n",
    "        \n",
    "    def serve_forever(self, interval=0.05):\n",
    "        threading.Thread(target=super().serve_forever, args=(interval,), daemon=True).start()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading issues: 300/4071      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Mar/2019 18:34:04] \"GET /cache?filters=gANdcQBYEAAAAHNwcmludF9taWxlc3RvbmVxAVgCAAAAPT1xAlgDAAAAMy4wcQOHcQRhLg== HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2019 18:34:05] \"GET /cache?filters=gANdcQBYEAAAAHNwcmludF9taWxlc3RvbmVxAVgCAAAAPT1xAlgDAAAAMy4wcQOHcQRhLg== HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading issues: 400/4071      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Mar/2019 18:34:06] \"GET /cache?filters=gANdcQBYEAAAAHNwcmludF9taWxlc3RvbmVxAVgCAAAAPT1xAlgDAAAAMy4wcQOHcQRhLg== HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2019 18:34:07] \"GET /cache?filters=gANdcQBYEAAAAHNwcmludF9taWxlc3RvbmVxAVgCAAAAPT1xAlgDAAAAMy4wcQOHcQRhLg== HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading issues: 500/4071      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Mar/2019 18:34:08] \"GET /cache?filters=gANdcQBYEAAAAHNwcmludF9taWxlc3RvbmVxAVgCAAAAPT1xAlgDAAAAMy4wcQOHcQRhLg== HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading issues: 600/4071      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Mar/2019 18:34:09] \"GET /cache?filters=gANdcQBYEAAAAHNwcmludF9taWxlc3RvbmVxAVgCAAAAPT1xAlgDAAAAMy4wcQOHcQRhLg== HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2019 18:34:10] \"GET /cache?filters=gANdcQBYEAAAAHNwcmludF9taWxlc3RvbmVxAVgCAAAAPT1xAlgDAAAAMy4wcQOHcQRhLg== HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading issues: 700/4071      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Mar/2019 18:34:11] \"GET /cache?filters=gANdcQBYEAAAAHNwcmludF9taWxlc3RvbmVxAVgCAAAAPT1xAlgDAAAAMy4wcQOHcQRhLg== HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading issues: 800/4071      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Mar/2019 18:34:12] \"GET /cache?filters=gANdcQBYEAAAAHNwcmludF9taWxlc3RvbmVxAVgCAAAAPT1xAlgDAAAAMy4wcQOHcQRhLg== HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading issues: 900/4071      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Mar/2019 18:34:13] \"GET /cache?filters=gANdcQBYEAAAAHNwcmludF9taWxlc3RvbmVxAVgCAAAAPT1xAlgDAAAAMy4wcQOHcQRhLg== HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 4071/4071      \n",
      "Downloading issues: 700/4071      "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    manager\n",
    "except NameError:\n",
    "    manager = RedmineCacheManager()\n",
    "rs = RedmineServer((\"localhost\", 11649), manager)\n",
    "rs.serve_forever(0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def decode(string):\n",
    "    b = base64.b64decode(string)\n",
    "    return pickle.loads(b)\n",
    "\n",
    "class RedmineClient():\n",
    "    _url = \"http://localhost:11649/\"\n",
    "    def __init__(self):\n",
    "        self.session = requests.Session()\n",
    "    def get_all(self):\n",
    "        r = self.session.get(self._url + \"cache\" + \"?issues=all\")\n",
    "        r.raise_for_status()\n",
    "        return decode(r.content.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs.shutdown()\n",
    "# rs.manager.stop()\n",
    "# rs.socket.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capi = importlib.reload(capi)\n",
    "# api = capi.IssuetrackerAPI('issue.pbsbiotech.com', 'nstarkweather', 'kookychemist')\n",
    "\n",
    "# # url = capi.uj(api._base_url, api._issues_url + \".json\")\n",
    "# # now = datetime.datetime.now()\n",
    "# # params = {\"updated_on\": \">=\" + now.isoformat()}\n",
    "# # print(now)\n",
    "# # url += \"?\" + urllib.parse.urlencode(params)\n",
    "# # r = api._sess.get(url, auth=api._auth)\n",
    "\n",
    "# # url\n",
    "\n",
    "# # r.content\n",
    "\n",
    "# _=next(api.download_issues())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
