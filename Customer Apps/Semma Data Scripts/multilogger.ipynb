{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gmv_keys = [\n",
    "    'temperature.output', \n",
    "    'temperature.man', \n",
    "    'temperature.interlocked', \n",
    "    'temperature.pv', \n",
    "    'temperature.sp', \n",
    "    'temperature.error', \n",
    "    'temperature.mode', \n",
    "    'agitation.output', \n",
    "    'agitation.man', \n",
    "    'agitation.interlocked', \n",
    "    'agitation.pv', \n",
    "    'agitation.sp', \n",
    "    'agitation.error', \n",
    "    'agitation.mode', \n",
    "    'ph.manUp',\n",
    "    'ph.outputDown',\n",
    "    'ph.error',\n",
    "    'ph.pv',\n",
    "    'ph.sp',\n",
    "    'ph.manDown',\n",
    "    'ph.outputUp',\n",
    "    'ph.mode',\n",
    "    'ph.interlocked',\n",
    "    'do.manUp',\n",
    "    'do.outputDown',\n",
    "    'do.error',\n",
    "    'do.pv',\n",
    "    'do.sp',\n",
    "    'do.manDown',\n",
    "    'do.outputUp',\n",
    "    'do.mode',\n",
    "    'do.interlocked',\n",
    "    'maingas.error',\n",
    "    'maingas.man',\n",
    "    'maingas.mode',\n",
    "    'maingas.pv',\n",
    "    'maingas.interlocked',\n",
    "    'MFCs.air',\n",
    "    'MFCs.n2',\n",
    "    'MFCs.o2',\n",
    "    'MFCs.co2',\n",
    "    'condenser.output',\n",
    "    'condenser.man',\n",
    "    'condenser.pv',\n",
    "    'condenser.sp', \n",
    "    'condenser.error', \n",
    "    'condenser.mode',\n",
    "    'pressure.error',\n",
    "    'pressure.pv',\n",
    "    'level.error',\n",
    "    'level.pv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from hello.hello3 import open_hello, NotLoggedInError\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import sys\n",
    "\n",
    "class _HelloLoggerTask(threading.Thread):\n",
    "    def __init__(self, ip, tag, vars, poll_interval=2, start_time=None):\n",
    "        \n",
    "        super().__init__(daemon=True)\n",
    "        # Config\n",
    "        self._ip = ip\n",
    "        self._vars = self._parse_vars(vars)\n",
    "        self._tag = tag\n",
    "        self.poll_interval = 5\n",
    "        \n",
    "        # Runtime\n",
    "        self._data = {}\n",
    "        self._h = None\n",
    "        self._start_time = start_time\n",
    "        \n",
    "        self._iflag = threading.Event()\n",
    "        self._fstop = threading.Event()\n",
    "        \n",
    "    def stop(self):\n",
    "        self._fstop.set()\n",
    "        \n",
    "    def get_tagged_vars(self):\n",
    "        tv = [self._tag + '.TimeStamp.Last', self._tag + '.Elapsed Time.hr']\n",
    "        tv.extend(\".\".join((self._tag, k1, k2)) for k1, k2 in self._vars)\n",
    "        return tv\n",
    "        \n",
    "    @property\n",
    "    def tag(self):\n",
    "        return self._tag\n",
    "    \n",
    "    def wait_for_initialized(self, timeout=10):\n",
    "        self._iflag.wait(timeout)\n",
    "        \n",
    "    def _query(self, h, start_time, recorded, next_run):\n",
    "        \n",
    "        # An existential question - when did the query actually occur?\n",
    "        # Did it occur as soon as the request was sent, after it was\n",
    "        # recieved, or halfway between the two? The most likely scenario\n",
    "        # for a delayed response is that our server software is choking \n",
    "        # for some reason, so use the timestamp immediately after return\n",
    "        # as the best estimate. Otherwise, the data parsing should be fast\n",
    "        # enough that the error would be measurable in microseconds. \n",
    "        \n",
    "        # The loop is here to retry \"infinitely\" until next_run (code\n",
    "        # will re-run anyway), the stop flag is set, or success. \n",
    "        # This silently swallows errors but that's fine for a proof of\n",
    "        # concept of this scale. \n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                mv = h.gpmv()\n",
    "            except Exception:\n",
    "                if time.time() > next_run or self._fstop.is_set():\n",
    "                    return\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        t = datetime.now()  \n",
    "        data = [t, (start_time - t).total_seconds() / 3600]\n",
    "\n",
    "        for k1, k2 in recorded:\n",
    "            v = mv[k1][k2]\n",
    "            data.append(v)\n",
    "        self.data = data  # \"Atomic\"\n",
    "        \n",
    "    def run(self):\n",
    "        \n",
    "        # create some locals for brevity\n",
    "        self._h = h = open_hello(self._ip)\n",
    "\n",
    "        if self._start_time is None:\n",
    "            self._start_time = datetime.now()\n",
    "        start_time = self._start_time\n",
    "        \n",
    "        recorded = self._vars\n",
    "        \n",
    "        # Initial query so that self.data isn't junk\n",
    "        \n",
    "        self._query(h, start_time, recorded)\n",
    "        self._iflag.set()\n",
    "        \n",
    "        while not self._fstop.is_set():\n",
    "            next_run = time.time() + self.poll_interval\n",
    "            self._query(h, start_time, recorded, next_run)\n",
    "\n",
    "            left = next_run - time.time()\n",
    "            if left > 0:\n",
    "                self._fstop.wait(left)\n",
    "        \n",
    "    def _parse_vars(self, vars):\n",
    "        seen = set()\n",
    "        keys = []\n",
    "        for k in vars:\n",
    "            if k in seen:\n",
    "                raise ValueError(\"Duplicate key found: %r\"%k)\n",
    "            if k not in _gmv_keys:\n",
    "                raise ValueError(\"Invalid key: %r\"%k)\n",
    "            seen.add(k)\n",
    "            try:\n",
    "                k1, k2 = k.split(\".\")\n",
    "            except ValueError:  # no \".\", bad key\n",
    "                raise ValueError(\"%r is an invalid key\" % k) from None\n",
    "            keys.append((k1, k2))\n",
    "        return tuple(keys)\n",
    "        \n",
    "        \n",
    "class HelloMultiLogger(threading.Thread):\n",
    "    def __init__(self, vars, sample_interval=10):\n",
    "        \n",
    "        super().__init__(daemon=True)\n",
    "        self._tasks = []\n",
    "        self._check_vars(vars)\n",
    "        self._vars = vars\n",
    "        self._sample_interval = sample_interval\n",
    "        self._ufuncs = []\n",
    "        self._running = False\n",
    "        self._fstop = threading.Event()\n",
    "        \n",
    "    def _check_vars(self, vars):\n",
    "        for v in vars:\n",
    "            if v not in _gmv_keys:\n",
    "                raise ValueError(\"Invalid key: %s\" % v)\n",
    "        \n",
    "    def add_callback(self, cb):\n",
    "        if cb in self._ufuncs:\n",
    "            return\n",
    "        self._ufuncs.append(cb)\n",
    "        \n",
    "    def remove_callback(self, cb):\n",
    "        try:\n",
    "            self._ufuncs.remove(cb)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "    def stop(self):\n",
    "        for t in self._tasks:\n",
    "            t.stop()\n",
    "        for t in self._tasks:\n",
    "            t.join()\n",
    "        self._fstop.set()\n",
    "        self.join()\n",
    "        \n",
    "    def add_logger(self, ip, tag, poll_interval=2, start=False, start_time=None):\n",
    "        if self.is_alive():\n",
    "            raise ValueError(\"Can't add tasks to already-running data logger.\")\n",
    "        task = _HelloLoggerTask(ip, tag, self._vars, poll_interval)\n",
    "        if start:\n",
    "            task.start()\n",
    "        self._tasks.append(task)\n",
    "        return task\n",
    "    \n",
    "    def start(self):\n",
    "        self._running = True\n",
    "        for t in self._tasks:\n",
    "            if not t.is_alive():\n",
    "                t.start()\n",
    "        super().start()\n",
    "        \n",
    "    def _do_callback(self, ev, payload):\n",
    "        for cb in self._ufuncs:\n",
    "            try:\n",
    "                cb(ev, payload)\n",
    "            except Exception as e:\n",
    "                sys.stderr.write(\"Error processing callback: %s\\n\" % str(e))\n",
    "    \n",
    "    def _send_update_cb(self, data):\n",
    "        self._do_callback('ML_LOG_DATA', data)\n",
    "        \n",
    "    def _send_begin_cb(self):\n",
    "        # the order of data sent each iteration is constant and never changes\n",
    "        order = [\"Timestamp\", \"Elapsed Time(hr)\"]\n",
    "        for t in self._tasks:\n",
    "            order.extend(t.get_tagged_vars())\n",
    "        self._do_callback(\"ML_BEGIN_LOG\", order)\n",
    "        \n",
    "    def _send_end_cb(self):\n",
    "        self._do_callback(\"ML_END_LOG\", None)\n",
    "        \n",
    "    def run(self):\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        for t in self._tasks:\n",
    "            t.wait_for_initialized()\n",
    "        \n",
    "        self._send_begin_cb()\n",
    "        while not self._fstop.is_set():\n",
    "            \n",
    "            # I went back on forth on the best way to get the data off\n",
    "            # each thread when it was time to log. The format of each data\n",
    "            # object is a list of tuples, and the assignment of the instance\n",
    "            # attribute is atomic. Therefore, just grabbing the data object \n",
    "            # without bothering with event flags or locks is fine, assuming CPython. \n",
    "            \n",
    "            ts = datetime.now()\n",
    "            next_run = time.time() + self._sample_interval\n",
    "            \n",
    "            data = [ts, (ts-start_time).total_seconds() / 3600]\n",
    "            for t in self._tasks:\n",
    "                data.extend(t.data)\n",
    "            self._send_update_cb(data)\n",
    "            \n",
    "            left = next_run - time.time()\n",
    "            if left > 0:\n",
    "                self._fstop.wait(left)\n",
    "        self._send_end_cb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(event, payload):\n",
    "    if event == \"ML_BEGIN_LOG\":\n",
    "        pass\n",
    "    elif event == \"ML_LOG_DATA\":\n",
    "        pass\n",
    "    elif event == \"ML_END_LOG\":\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Unknown event: %r\"%event)\n",
    "\n",
    "def my_callback(event, payload):\n",
    "    print(\"Got event:\", event)\n",
    "    if event == \"ML_BEGIN_LOG\":\n",
    "        print(*payload)\n",
    "    elif event == \"ML_LOG_DATA\":\n",
    "        print(*payload)\n",
    "    elif event == \"ML_END_LOG\":\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Unknown event: %r\"%event)\n",
    "        \n",
    "def csv_writer(filename):\n",
    "    f = None\n",
    "    def csv_writer_cb(event, payload):\n",
    "        nonlocal f\n",
    "        if event == \"ML_BEGIN_LOG\":\n",
    "            f = open(filename, 'w')\n",
    "            f.write(\",\".join(map(str, payload)))\n",
    "            f.write(\"\\n\")\n",
    "        elif event == \"ML_LOG_DATA\":\n",
    "            f.write(\",\".join(map(str, payload)))\n",
    "            f.write(\"\\n\")\n",
    "        elif event == \"ML_END_LOG\":\n",
    "            f.close()\n",
    "        else:\n",
    "            raise ValueError(\"Unknown event: %r\"%event)\n",
    "    \n",
    "    return csv_writer_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got event: ML_BEGIN_LOG\n",
      "Timestamp Elapsed Time(hr) R&D1.TimeStamp.Last R&D1.Elapsed Time.hr R&D1.agitation.pv R&D1.temperature.pv R&D2.TimeStamp.Last R&D2.Elapsed Time.hr R&D2.agitation.pv R&D2.temperature.pv\n",
      "Got event: ML_LOG_DATA\n",
      "2018-10-01 16:53:28.200363 0.0002878958333333333 2018-10-01 16:53:28.187398 -0.0002856797222222222 0 27.067668914794922 2018-10-01 16:53:27.982377 -0.00022817555555555558 0 31.601276397705078\n",
      "Got event: ML_LOG_DATA\n",
      "2018-10-01 16:53:31.200514 0.001121271111111111 2018-10-01 16:53:28.380205 -0.0003392372222222222 0 27.067668914794922 2018-10-01 16:53:27.982377 -0.00022817555555555558 0 31.601276397705078\n",
      "Got event: ML_LOG_DATA\n",
      "2018-10-01 16:53:34.202049 0.0019550308333333333 2018-10-01 16:53:33.353377 -0.001720673888888889 0 27.067981719970703 2018-10-01 16:53:32.995425 -0.0016206888888888888 0 31.605201721191406\n",
      "Got event: ML_LOG_DATA\n",
      "2018-10-01 16:53:37.203109 0.002788658611111111 2018-10-01 16:53:33.353377 -0.001720673888888889 0 27.067981719970703 2018-10-01 16:53:32.995425 -0.0016206888888888888 0 31.605201721191406\n",
      "Got event: ML_LOG_DATA\n",
      "2018-10-01 16:53:40.203503 0.003622101388888889 2018-10-01 16:53:38.371119 -0.0031144911111111112 0 27.0675106048584 2018-10-01 16:53:38.015544 -0.003015166388888889 0 31.602066040039062\n"
     ]
    }
   ],
   "source": [
    "vars_i_care_about = [\n",
    "    'agitation.pv',\n",
    "    'temperature.pv'\n",
    "]\n",
    "\n",
    "ml = HelloMultiLogger(vars_i_care_about, 3)\n",
    "\n",
    "ml.add_logger(\"192.168.1.14\", \"R&D1\", 1)\n",
    "ml.add_logger(\"192.168.1.16\", \"R&D2\", 1)\n",
    "\n",
    "ml.add_callback(my_callback)\n",
    "ml.add_callback(csv_writer(\"test_multilogger.csv\"))\n",
    "\n",
    "ml.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got event: ML_END_LOG\n"
     ]
    }
   ],
   "source": [
    "ml.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
