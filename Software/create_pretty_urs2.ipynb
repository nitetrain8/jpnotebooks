{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.software_frs import frs_traceability2\n",
    "FRS = frs_traceability2\n",
    "from officelib.xllib import *\n",
    "from officelib.const import xlconst as xlc\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "from scripts.tools.issuetracker import IssuetrackerAPI\n",
    "from datetime import datetime\n",
    "\n",
    "import jpnotebooks.Software.SDLC_traceability_tools.issuetracker_item_extracter as iie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cache = None\n",
    "_age = None\n",
    "def _download_issues():\n",
    "    api = IssuetrackerAPI('issue.pbsbiotech.com', 'nstarkweather', 'kookychemist')\n",
    "    return api.download_issues(\"pbssoftware\", status_id=\"*\")\n",
    "\n",
    "def get_issues():\n",
    "    global _cache, _age\n",
    "    if not _cache or (datetime.now() - _age).total_seconds() > (8*3600):  # 8 hr\n",
    "        _cache = _download_issues()\n",
    "        _age = datetime.now()\n",
    "    return _cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_relevant_issues(issues, rel_cb):\n",
    "    relevant = {}\n",
    "    for v in issues.values():\n",
    "        if rel_cb(v):\n",
    "                relevant[v.id] = v\n",
    "    return relevant\n",
    "\n",
    "def load_frs_from_issuetracker(rel_cb):\n",
    "    issues = get_issues()\n",
    "    relevant = filter_relevant_issues(issues, rel_cb)\n",
    "    \n",
    "    reqs = iie.IssuetrackerParser([\"URS\", \"FRS\", \"SDS\"]).parse_all(relevant.values())\n",
    "    return reqs, relevant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paste_data(ws, data):\n",
    "    cells = ws.Cells\n",
    "    cr = cells.Range\n",
    "    \n",
    "    di = 2\n",
    "    hi = 3\n",
    "    \n",
    "    header_start = cr(\"A1\")\n",
    "    \n",
    "    frs_start = cr(\"A2\")\n",
    "    frs_end = header_start.Offset(len(data), 1)\n",
    "\n",
    "    id_start = frs_start.Offset(1, 3)\n",
    "    id_end = frs_end.Offset(1, 3)\n",
    "    \n",
    "\n",
    "    paste_start = header_start\n",
    "    paste_end = frs_end.Offset(1, len(data[0]))\n",
    "\n",
    "    xl = ws.Application\n",
    "    \n",
    "    with screen_lock(xl):\n",
    "        print(\"Pasting test data\")\n",
    "        paste_range = cr(paste_start, paste_end)\n",
    "        paste_range.Clear()\n",
    "        cr(id_start, id_end).NumberFormat = \"@\"\n",
    "        cr(paste_range.Cells(1, 5), paste_range.Cells(len(data), 5)).NumberFormat = \"@\"\n",
    "        paste_range.Value2 = data         \n",
    "\n",
    "        # This has to come before IndentLevel is set,\n",
    "        # or it gets fucked up for some reason even\n",
    "        # though it seems to work correctly when performing\n",
    "        # the operation manually\n",
    "        print(\"Applying alignment formatting\")\n",
    "        col = paste_range.Columns(2)\n",
    "        col.ColumnWidth = 100\n",
    "        col.VerticalAlignment = xlc.xlTop\n",
    "        paste_range.Columns(2).WrapText = True\n",
    "        \n",
    "        # Vertical alignment should be top for all\n",
    "        for i in range(1, len(data[0])+1):\n",
    "            paste_range.Columns(i).VerticalAlignment = xlc.xlTop\n",
    "            paste_range.Columns(i).HorizontalAlignment = xlc.xlLeft\n",
    "        \n",
    "        # Create a new range to iterate over\n",
    "        # this improves performance by minimizing the number of \n",
    "        # calls that have to be across the COM server to apply\n",
    "        # the indents\n",
    "    \n",
    "        print(\"Applying row formatting\")\n",
    "        indent_range = cr(paste_start, paste_start.Offset(len(data), 2))\n",
    "        for i, (d, row) in enumerate(zip(data, indent_range.Rows), 1):\n",
    "            count = d[0].count(\".\") * 2\n",
    "            row.IndentLevel = count\n",
    "            if count == 0:\n",
    "                rint = paste_range.Rows(i).Interior\n",
    "                rint.Pattern = xlc.xlSolid\n",
    "                rint.PatternColorIndex = xlc.xlAutomatic\n",
    "                rint.ThemeColor = xlc.xlThemeColorAccent6\n",
    "                rint.TintAndShade = 0.6\n",
    "                \n",
    "        # Document header row formatting\n",
    "        rint = paste_range.Rows(1).Interior\n",
    "        rint.Pattern = xlc.xlSolid\n",
    "        rint.PatternColorIndex = xlc.xlAutomatic\n",
    "        rint.ThemeColor = xlc.xlThemeColorDark1\n",
    "        rint.TintAndShade = -0.249977111117893\n",
    "        \n",
    "        print(\"Applying column autofit\")\n",
    "        # fit after filter to account for width of filter icon\n",
    "        for i in (1, 3, 4, 5):\n",
    "            paste_range.Columns(i).AutoFit()\n",
    "\n",
    "        print(\"Applying row autofit\")\n",
    "        paste_range.Rows.AutoFit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from officelib.xllib import *\n",
    "import re\n",
    "\n",
    "# unlike the Reference class's item key, the key for the Node class\n",
    "# is (TYPE+FIRSTNUM, OTHERNUMS). e.g. ('URS123', '4.5') instead of\n",
    "# ('URS', '123.4.5')\n",
    "_imkey = re.compile(r\"(%s)(\\d+)\\.?([\\d\\.]*)\" % \"|\".join(['URS', 'FRS', 'SDS'])).match\n",
    "\n",
    "def key_match(key):\n",
    "    m = _imkey(key)\n",
    "    if m:\n",
    "        type, first, others = m.groups()\n",
    "        return type+first, others\n",
    "    return key, \"\"\n",
    "\n",
    "def build_frs_tree(all_items, type):\n",
    "    root = FRS.Root(key_match)\n",
    "    for frs, req in all_items.items():\n",
    "        if req.type != type:\n",
    "            continue\n",
    "        node = root.add(frs, int(req.obs))\n",
    "        node.text = req.text\n",
    "        node.refs = req.refs\n",
    "        node.milestone = req.milestone\n",
    "        node.priority = req.priority\n",
    "    return root\n",
    "\n",
    "def make_paste_data2(reqs, typ):\n",
    "    data = [[\"URS Number\", \"Text\", \"References\", \"Criticality\", \"Release Version\", \"Sort Order\"]]\n",
    "    seen = {}\n",
    "    thekey = lambda req: [int(x or 0) for x in req.num.split(\".\")]\n",
    "    reqs = [r for r in reqs if r.type == typ]\n",
    "    for req in sorted(reqs, key=thekey):\n",
    "        rkey = req.type + req.num.split(\".\")[0]\n",
    "        if rkey in seen:\n",
    "            so = \"=R[-1]C + 1\"\n",
    "        else:\n",
    "            seen[rkey] = so = (len(seen) + 1) * 1000\n",
    "        data.append((req.tag, numberify(req.text), \"\\n\".join(req.refs), req.priority, req.milestone, so))\n",
    "    return data\n",
    "\n",
    "import re\n",
    "_numberify_sub = re.compile(r\"^(#+|\\*+)\", flags=re.MULTILINE).sub\n",
    "\n",
    "def numberify(text):\n",
    "    \n",
    "    stack = None\n",
    "    last = None\n",
    "\n",
    "    def _numberify(m):\n",
    "        nonlocal last, stack\n",
    "        s = m.group(1)\n",
    "        if s[0] == \"*\":\n",
    "            return \"  \" * len(s) + \"*\"\n",
    "        if last is None:\n",
    "            stack = [1]\n",
    "            last = s\n",
    "            lastn = 1\n",
    "            return \"  1)\"\n",
    "        else:\n",
    "            if len(s) < len(last):\n",
    "                stack.pop()\n",
    "            elif len(s) > len(last):\n",
    "                stack.append(0)\n",
    "            last = s\n",
    "            stack[-1] += 1\n",
    "            return \"  \" + \".\".join(map(str, stack)) + \")\"\n",
    "    return _numberify_sub(_numberify, text)\n",
    "\n",
    "def main(type='URS', rel_cb=lambda x: True):\n",
    "\n",
    "    issues = get_issues()\n",
    "    relevant = filter_relevant_issues(issues, rel_cb)\n",
    "    reqs = iie.IssuetrackerParser([\"URS\", \"FRS\", \"SDS\"]).parse_all(relevant.values())\n",
    "\n",
    "    xl = Excel()\n",
    "    with screen_lock(xl):\n",
    "        print(\"Compiling data for final matrix\")\n",
    "        data = make_paste_data2(reqs, type)  \n",
    "        ws = FRS.get_matrix_sheet(xl)\n",
    "        paste_data(ws, data)\n",
    "        print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading projects...\n",
      "Downloading issues: 1711/1711      \n",
      "Compiling data for final matrix\n",
      "Pasting test data\n",
      "Applying alignment formatting\n",
      "Applying row formatting\n",
      "Applying column autofit\n",
      "Applying row autofit\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "_ignore = {3194, 3287}\n",
    "#(globals().get(\"_cache\", None) or {}).clear()\n",
    "def relevant(i):\n",
    "    return (i.sprint_milestone == \"Legacy\" or i.sprint_milestone == '3.0') and i.id not in _ignore and i.status != \"Rejected\"\n",
    "\n",
    "trace_path = 'C:\\\\Users\\\\Nathan\\\\Documents\\\\Dropbox\\\\FRS'\n",
    "user_tests = 'FRS Tests 181127.xlsx'\n",
    "p1 = os.path.join(trace_path, user_tests)\n",
    "main('URS', relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = Excel()\n",
    "while True:\n",
    "    try:\n",
    "        wb = xl.Workbooks(1)\n",
    "        wb.Close(False)\n",
    "    except:\n",
    "        break\n",
    "xl.Quit()\n",
    "del xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rowify():\n",
    "    try:\n",
    "        xl\n",
    "    except NameError:\n",
    "        xl = Excel()\n",
    "    rows = xl.Selection.Value2\n",
    "    out = []\n",
    "    for tag, text in rows:\n",
    "        tag = \"*\" * tag.count(\".\") + \" \" + \"*\" + tag + \"*\"\n",
    "        \n",
    "        out.append(tag + \" \" + text)\n",
    "    return \"\\n\".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* *URS3910.4* All report types will use a standard file format such that the data can be imported into Microsoft Excel or LibreOffice.\n",
      "* *URS3910.5* Users will be able to generate reports from both active and archived databases.\n",
      "* *URS3910.6* Users will be able to clearly identify batches which span multiple databases.\n",
      "* *URS3910.7* Reports will include metadata that indicates batch name or timespan.\n"
     ]
    }
   ],
   "source": [
    "print(rowify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
