{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,urllib,json, logging, dateutil, queue, threading, networkx as nx, asyncio, aiohttp, gc, datetime\n",
    "from officelib.xllib import *\n",
    "from pywintypes import com_error\n",
    "import time\n",
    "\n",
    "_urljoin = urllib.parse.urljoin\n",
    "_urlencode = urllib.parse.urlencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConverterError(Exception):\n",
    "    pass\n",
    "\n",
    "class _RedmineConverter():\n",
    "    def __init__(self):\n",
    "        self._converters = {}\n",
    "        \n",
    "    def Register(self, kls):\n",
    "        self._converters[kls] = dict(kls._converter_table)\n",
    "        return kls  # allow function use as decorator\n",
    "        \n",
    "    def Deserialize(self, jobj, kls):\n",
    "        try:\n",
    "            tbl = self._converters[kls]\n",
    "        except KeyError:\n",
    "            raise\n",
    "        \n",
    "        obj = kls()\n",
    "        for key, val in jobj.items():\n",
    "            conv = tbl.get(key)\n",
    "            if conv:\n",
    "                if conv in self._converters:\n",
    "                    val = self.Deserialize(val, conv)\n",
    "                else:\n",
    "                    val = conv(val)\n",
    "            else:\n",
    "                pass\n",
    "                # pass : use val as-is (string)\n",
    "            setattr(obj, key, val)\n",
    "            \n",
    "        for key in tbl.keys():\n",
    "            if key not in jobj:\n",
    "                setattr(obj, key, None)\n",
    "        return obj\n",
    "            \n",
    "RedmineConverter = _RedmineConverter()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RedmineConverter.Register\n",
    "class Resource():\n",
    "    _converter_table = [\n",
    "        (\"name\", str),\n",
    "        (\"id\", int),\n",
    "        (\"value\", str)\n",
    "    ]\n",
    "    def __str__(self):\n",
    "        return f\"<{self.__class__.__name__} {self.name}, id={self.id}, v={repr(self.value)}>\"\n",
    "    __repr__ = __str__\n",
    "    \n",
    "    \n",
    "@RedmineConverter.Register\n",
    "class User():\n",
    "    _converter_table = [\n",
    "        (\"name\", str),\n",
    "        (\"id\", int)\n",
    "    ]\n",
    "    def __str__(self):\n",
    "        return f\"<{self.__class__.__name__} {self.name}, id={self.id}>\"\n",
    "    __repr__ = __str__\n",
    "    \n",
    "\n",
    "def Datetime(d):\n",
    "    return dateutil.parser.parse(d)\n",
    "\n",
    "\n",
    "def CustomFields(cf):\n",
    "    fields = {}\n",
    "    for f in cf:\n",
    "        fields[f['name']] = RedmineConverter.Deserialize(f, Resource)\n",
    "    return fields\n",
    "\n",
    "def Parent(p):\n",
    "    return p['id']\n",
    "\n",
    "@RedmineConverter.Register\n",
    "class Issue():\n",
    "    \n",
    "    _converter_table = [\n",
    "        (\"author\", User),\n",
    "        (\"custom_fields\", CustomFields),\n",
    "        (\"fixed_version\", Resource),\n",
    "        (\"status\", Resource),\n",
    "        (\"created_on\", Datetime),\n",
    "        (\"updated_on\", Datetime),\n",
    "        (\"id\", int),\n",
    "        (\"project\", Resource),\n",
    "        (\"priority\", Resource),\n",
    "        (\"due_date\", Datetime),\n",
    "        (\"tracker\", Resource),\n",
    "        (\"parent\", Parent),\n",
    "        (\"closed_on\", Datetime),\n",
    "        (\"start_date\", Datetime),\n",
    "        (\"assigned_to\", User),\n",
    "        (\"estimated_hours\", float)\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<{self.__class__.__name__}: '{self.subject}'>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client():\n",
    "    def __init__(self, url, key):\n",
    "        if not url.startswith(\"http\"):\n",
    "            url = \"https://\"+url\n",
    "        self._url = url\n",
    "        self._key = key\n",
    "        self._sess = requests.Session()\n",
    "        self._headers = {'X-Redmine-API-Key': self._key}\n",
    "        self._Issues = None\n",
    "        \n",
    "    def _rawget(self, url, headers):\n",
    "        r = self._sess.get(url, headers=headers)\n",
    "        r.raise_for_status()\n",
    "        return r\n",
    "    \n",
    "    def _prep(self, path, opts):\n",
    "        base = _urljoin(self._url, path)\n",
    "        qs = _urlencode(opts)\n",
    "        url = f\"{base}?{qs}\"\n",
    "        return url, self._headers\n",
    "    \n",
    "    def get(self, path, opts):\n",
    "        url, headers = self._prep(path, opts)\n",
    "        return self._rawget(url, headers)\n",
    "    \n",
    "    async def get_async(self, session, path, opts):\n",
    "        url, headers = self._prep(path, opts)\n",
    "        async with session.get(url, headers=headers) as r:\n",
    "            r.raise_for_status()\n",
    "            return await r.json()\n",
    "        \n",
    "    def superget(self, key, path, opts=None):\n",
    "        base = _urljoin(self._url, path)\n",
    "        opts = opts or {}\n",
    "        pool = RedmineSuperPool(self._headers, key, base, opts)\n",
    "        results = pool.wait()\n",
    "        count = pool.total_count()\n",
    "        assert len({x['id'] for x in results}) == count\n",
    "        return results\n",
    "            \n",
    "    @property\n",
    "    def Issues(self):\n",
    "        if self._Issues is None:\n",
    "            self._Issues = IssuesClient(self)\n",
    "        return self._Issues\n",
    "    \n",
    "    def close(self):\n",
    "        self._Issues = None\n",
    "     \n",
    "def _step_range(limit, total_count, ioffset):\n",
    "        start = ioffset\n",
    "        end = total_count - 1\n",
    "        step = limit\n",
    "        \n",
    "        # extra is the amount needed to ensure\n",
    "        # the final iteration includes the \"stop\"\n",
    "        # value\n",
    "        extra = step - (end - start) % step \n",
    "        stop = end + extra\n",
    "        yield from range(start, stop, step)\n",
    "        \n",
    "# def test_step_range(total_count=1021):\n",
    "#     limit = 100\n",
    "#     for i in _step_range(limit, total_count, limit):\n",
    "#         pass\n",
    "#     ilast = total_count - 1\n",
    "#     assert (i + limit > ilast)\n",
    "\n",
    "# for i in range(800, 1200):\n",
    "#     test_step_range(i)\n",
    "    \n",
    "class RedmineSuperPool:\n",
    "    def __init__(self, headers, key, path, opts):\n",
    "        self._headers = headers\n",
    "        self._path = path\n",
    "        self._opts = opts\n",
    "        self._key = key\n",
    "        \n",
    "        self._thread = threading.Thread(None, target=self._run, daemon=True)\n",
    "        self._stop = False\n",
    "        self._results = []\n",
    "        self._total_count = 0\n",
    "        self._thread.start()\n",
    "        \n",
    "        \n",
    "    def _run(self):\n",
    "        self._stop = False\n",
    "        main = self._main()\n",
    "        asyncio.run(main)\n",
    "        \n",
    "    def wait(self):\n",
    "        self._thread.join()\n",
    "        return self._results\n",
    "    \n",
    "    def total_count(self):\n",
    "        return self._total_count\n",
    "        \n",
    "    def _urlify(self, path, opts):\n",
    "        return f\"{path}?{_urlencode(opts)}\"\n",
    "        \n",
    "    async def _main(self):\n",
    "        loop = asyncio.get_running_loop()\n",
    "        async with aiohttp.ClientSession(headers=self._headers) as session:\n",
    "            \n",
    "            # first one gets total count\n",
    "            opts = self._opts\n",
    "            opts['limit'] = limit = 100\n",
    "            opts['offset'] = offset = 0\n",
    "            url = self._urlify(self._path, opts)\n",
    "            j = await self._fetch_result(session, url)\n",
    "            \n",
    "            self._total_count = total_count = j['total_count']\n",
    "\n",
    "            tasks = []\n",
    "            for offset in _step_range(limit, total_count, limit):\n",
    "                opts['offset'] = offset\n",
    "                url = self._urlify(self._path, opts)\n",
    "                task = loop.create_task(self._fetch_result(session, url))\n",
    "                tasks.append(task)\n",
    "            await asyncio.gather(*tasks)\n",
    "            assert len(self._results) == total_count, (len(self._results), total_count)\n",
    "                \n",
    "    async def _fetch_result(self, session, url):\n",
    "        j = await self._fetch(session, url)\n",
    "        self._results.extend(j[self._key])\n",
    "        return j\n",
    "            \n",
    "    async def _fetch(self, session, url):\n",
    "        ret = await session.get(url)\n",
    "        ret.raise_for_status()\n",
    "        return await ret.json()\n",
    "        \n",
    "    \n",
    "class IssuesClient():\n",
    "    def __init__(self, client):\n",
    "        self._client = client\n",
    "        \n",
    "    def filter(self, /, **opts):\n",
    "        raw = self._client.superget(\"issues\", \"/issues.json\", opts)\n",
    "        def parse(x):\n",
    "            return RedmineConverter.Deserialize(x, Issue)\n",
    "        return [parse(x) for x in raw]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = \"7676add9cac6631410403671cdd7850311987898\"\n",
    "# client = Client(\"issue.pbsbiotech.com\",key)\n",
    "# client.superget(\"issues\", \"/issues.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Column:\n",
    "    def __init__(self, name, idx, header=None):\n",
    "        self.name = name\n",
    "        self.idx = idx\n",
    "        self.header = header or self.name\n",
    "        self.top = None\n",
    "        \n",
    "class ColumnConfig:\n",
    "    def __init__(self, cells, row=1):\n",
    "        self.cells = cells\n",
    "        self.cr = cells.Range\n",
    "        self.columns = {}\n",
    "        self._row = row\n",
    "        self._min = 0\n",
    "        self._max = 0\n",
    "        self._get_cache = {}\n",
    "        self._list = []\n",
    "        self._target_cache = {}\n",
    "        \n",
    "    def set_row(self, r):\n",
    "        self._row = r\n",
    "        \n",
    "    def add(self, name, idx, header=None):\n",
    "        if name in self.columns:\n",
    "            raise ValueError(name)\n",
    "        col = Column(name, idx, header)\n",
    "        self.columns[name] = col\n",
    "        self.columns[idx] = col\n",
    "        self._list.append(col)\n",
    "        col.top = self.cells(1, idx + 1)\n",
    "        \n",
    "        if idx < self._min:\n",
    "            self._min = idx\n",
    "        elif idx > self._max:\n",
    "            self._max = idx\n",
    "        \n",
    "    def get(self, v):\n",
    "        key = self._row, self.columns[v]\n",
    "        col = self._get_cache.get(key, None)\n",
    "        if col is None:\n",
    "            col = self.columns[v].top.GetOffset(self._row - 1, 0)\n",
    "            self._get_cache[key] = col\n",
    "        return col\n",
    "\n",
    "    def clear_cache(self):\n",
    "        self._get_cache.clear()\n",
    "        self._target_cache.clear()\n",
    "    \n",
    "    def target(self):\n",
    "        t = self._target_cache.get(self._row, None)\n",
    "        if t is None:\n",
    "            c1 = self.get(self._min)\n",
    "            c2 = self.get(self._max)\n",
    "            t = self.cr(c1, c2)\n",
    "            self._target_cache[self._row] = t\n",
    "        return t\n",
    "    \n",
    "    def apply_data(self, data):\n",
    "        target = self.target()\n",
    "        row = [None] * target.Columns.Count\n",
    "        for k, v in data.items():\n",
    "            col = self.columns[k]\n",
    "            row[col.idx - self._min] = v\n",
    "        target.Value2 = [row]\n",
    "           \n",
    "def resource_name(r):\n",
    "    if r is not None:\n",
    "        return r.name\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "class BaseVisitor:\n",
    "    def __init__(self, ws, g, issues):\n",
    "        self.ws = ws\n",
    "        self.g = g\n",
    "        if not isinstance(issues, dict):\n",
    "            issues = {i.id:i for i in issues}\n",
    "        self.issues = issues\n",
    "        self.cells = ws.Cells\n",
    "        self.cr = self.cells.Range\n",
    "        self.nseen = 0\n",
    "        self.depth = 0\n",
    "        self.stack = [0]\n",
    "        \n",
    "        self.columns = ColumnConfig(self.cells, 3)\n",
    "        \n",
    "        spec = [\n",
    "            \"#\",\n",
    "            \"Issue\",\n",
    "            \"Name\",\n",
    "            \"Assignee(s)\",\n",
    "            \"% Done\",\n",
    "            \"Status\",\n",
    "            \"Hours\",\n",
    "            \"Priority\",\n",
    "            \"Last Update\",\n",
    "            \"Due Date\",\n",
    "            \"Weighted Score\",\n",
    "            \"Deliverable ID\",\n",
    "            \"Date1\",\n",
    "            \"Notes/Current Action(s)\",\n",
    "        ]\n",
    "        for i, s in enumerate(spec):\n",
    "            self.columns.add(s, i)\n",
    "            \n",
    "    def _indent(self):\n",
    "        self.depth += 1\n",
    "        self.stack.append(1)\n",
    "        \n",
    "    def _dedent(self, depth):\n",
    "        diff = self.depth - depth\n",
    "        self.depth = depth\n",
    "        for _ in range(diff):\n",
    "            self.stack.pop()\n",
    "        self.stack[-1] += 1\n",
    "        \n",
    "    def _increment(self):\n",
    "        self.stack[-1] += 1\n",
    "        \n",
    "    def _outline_number(self):\n",
    "        if len(self.stack) == 1:\n",
    "            return str(self.stack[0]) + \".0\"\n",
    "        return \".\".join(map(str,self.stack))\n",
    "    \n",
    "    def _get(self, node):\n",
    "        return self.issues[node]\n",
    "    \n",
    "    def _make_data(self, iss):\n",
    "        data = {\n",
    "            \"#\":                       self._outline_number(),\n",
    "            \"Issue\":                   iss.id,\n",
    "            \"Name\":                    iss.subject,\n",
    "            \"Assignee(s)\":             resource_name(iss.assigned_to),\n",
    "            \"% Done\":                  iss.done_ratio / 100,\n",
    "            \"Status\":                  resource_name(iss.status),\n",
    "            \"Hours\":                   iss.estimated_hours or 0,\n",
    "            \"Priority\":                resource_name(iss.priority),\n",
    "            \"Weighted Score\":          \"\",\n",
    "            \"Deliverable ID\":          \"\",\n",
    "            \"Date1\":                   \"\",\n",
    "            \"Notes/Current Action(s)\": \"\",\n",
    "            \"Due Date\":                iss.due_date,\n",
    "            \"Last Update\":             iss.updated_on\n",
    "         }\n",
    "        return data\n",
    "    \n",
    "    def visit_all(self):\n",
    "        dfs_visit(self.g, self.visit)\n",
    "        \n",
    "    def _handle_depth(self, depth):\n",
    "        if depth > self.depth:\n",
    "            self._indent()\n",
    "        elif depth < self.depth:\n",
    "            self._dedent(depth)\n",
    "        else:\n",
    "            self._increment()\n",
    "    \n",
    "class PlanInitVisitor(BaseVisitor):\n",
    "    \n",
    "    def _format_row(self):\n",
    "        get = self.columns.get\n",
    "        outline = get(\"#\")\n",
    "        iid = get(\"Issue\")\n",
    "        name = get(\"Name\")\n",
    "        assignee = get(\"Assignee(s)\")\n",
    "        done = get(\"% Done\")\n",
    "        status = get(\"Status\")\n",
    "        hours = get(\"Hours\")\n",
    "        due = get(\"Due Date\")\n",
    "        priority = get(\"Priority\")\n",
    "        updated = get(\"Last Update\")\n",
    "        target = self.columns.target()\n",
    "        \n",
    "        indent = len(self.stack) - 1\n",
    "        \n",
    "        # reset target range\n",
    "        target.Font.Bold = False\n",
    "        target.IndentLevel = 0\n",
    "        target.Font.Size = 10\n",
    "        if indent == 0:\n",
    "            self._fill(target, 'gray')\n",
    "        else:\n",
    "            self._fill(target, 'none')\n",
    "        \n",
    "        outline.Font.Bold = True\n",
    "        if indent == 0:  # major heading\n",
    "            name.Font.Bold = True \n",
    "            done.Font.Bold = True\n",
    "            status.Font.Bold = True\n",
    "\n",
    "        outline.IndentLevel = indent\n",
    "        name.IndentLevel = indent\n",
    "        \n",
    "    def _fill(self, cell, op):\n",
    "        # copied from vba macro\n",
    "        i = cell.Interior\n",
    "        if op == 'gray':\n",
    "            i.Pattern = xlc.xlSolid\n",
    "            i.PatternColorIndex = xlc.xlAutomatic\n",
    "            i.ThemeColor = xlc.xlThemeColorDark1\n",
    "            i.TintAndShade = -0.14996795556505\n",
    "            i.PatternTintAndShade = 0\n",
    "        elif op == 'none':\n",
    "            i.Pattern = xlc.xlNone\n",
    "            i.TintAndShade = 0\n",
    "            i.PatternTintAndShade = 0\n",
    "        else:\n",
    "            raise ValueError(op)\n",
    "        \n",
    "    def visit(self, node, depth):\n",
    "        self._handle_depth(depth)\n",
    "        \n",
    "        iss = self._get(node)\n",
    "        data = self._make_data(iss)\n",
    "        \n",
    "        self._format_row()\n",
    "        self.columns.apply_data(data)\n",
    "        \n",
    "        outline = self.columns.get(\"#\")\n",
    "        iid = self.columns.get(\"Issue\")\n",
    "        \n",
    "        self._add_hyperlink(iid)\n",
    "        \n",
    "        # disable the \"number as text\" warning for the\n",
    "        # outline number and issue ID columns.\n",
    "        for c in (outline, iid):\n",
    "            try:\n",
    "                c.Errors.Item(xlc.xlNumberAsText).Ignore = True\n",
    "            except com_error:\n",
    "                # if there is no active error, the method throws an exception\n",
    "                pass \n",
    "        \n",
    "        self.nseen += 1\n",
    "        self.columns.set_row(self.nseen + 3)\n",
    "    \n",
    "    def _add_hyperlink(self, iid):\n",
    "        v = int(iid.Value2)\n",
    "        v = str(v)\n",
    "        href = \"https://issue.pbsbiotech.com/issues/\" + v\n",
    "        self.ws.Hyperlinks.Add(Anchor=iid, Address=href, TextToDisplay=v)\n",
    "        iid.Font.Underline = False\n",
    "    \n",
    "    def finish(self):\n",
    "        \n",
    "        # unpacking.....\n",
    "        get = self.columns.get\n",
    "        outline = get(\"#\").EntireColumn\n",
    "        iid = get(\"Issue\").EntireColumn\n",
    "        name = get(\"Name\").EntireColumn\n",
    "        assignee = get(\"Assignee(s)\").EntireColumn\n",
    "        done = get(\"% Done\").EntireColumn\n",
    "        status = get(\"Status\").EntireColumn\n",
    "        hours = get(\"Hours\").EntireColumn\n",
    "        due = get(\"Due Date\").EntireColumn\n",
    "        priority = get(\"Priority\").EntireColumn\n",
    "        updated = get(\"Last Update\").EntireColumn\n",
    "        \n",
    "        # set numbering formats\n",
    "        iid.NumberFormat = \"@\"\n",
    "        outline.NumberFormat = \"@\"\n",
    "        done.NumberFormat = \"0%\"\n",
    "        hours.NumberFormat = \"0.0\"\n",
    "        due.NumberFormat = \"m/d/yyyy\"\n",
    "        updated.NumberFormat = \"m/d - h:mm AM/PM\"\n",
    "        \n",
    "        # center these cells\n",
    "        for c in (done, status, hours, iid, priority, updated):\n",
    "            c.IndentLevel = 0\n",
    "            c.HorizontalAlignment = xlc.xlCenter\n",
    "            \n",
    "        # force all cells to not wrap...\n",
    "        for c in (outline, iid, name, assignee, done, status, hours, due,\n",
    "                 updated, priority):\n",
    "            self._force_nowrap(c)\n",
    "        \n",
    "        self._conditional_format_updated_recent(updated)\n",
    "        self._conditional_format_due_now(due)\n",
    "        \n",
    "                    \n",
    "        # Autofilter can be toggled before the no-wrap\n",
    "        # to account for dropdown arrow width, but\n",
    "        # this makes the cells wide. \n",
    "#         status.Cells(2,1).AutoFilter(1)\n",
    "        \n",
    "        self.columns.clear_cache()\n",
    "        \n",
    "    def _conditional_format_updated_recent(self, updated):\n",
    "        # based on macro recorded\n",
    "        # Conditional Formatting -> Highlight Cells Rules -> A Date Occurring -> Last 7 days\n",
    "        cond = updated.FormatConditions.Add(Type=xlc.xlTimePeriod, DateOperator=xlc.xlLast7Days)\n",
    "        cond.StopIfTrue = False\n",
    "        \n",
    "        # \"Green Fill with Dark Green Text\"\n",
    "        font = cond.Font; interior = cond.Interior\n",
    "        font.Color = -16752384\n",
    "        font.TintAndShade = 0\n",
    "        interior.PatternColorIndex = xlc.xlAutomatic\n",
    "        interior.Color = 13561798\n",
    "        interior.TintAndShade = 0\n",
    "        \n",
    "    def _conditional_format_due_now(self, due):\n",
    "        \"\"\"\n",
    "        Sets due date column to highlight tasks if they are \n",
    "        due on or earlier than the current date. \n",
    "        \n",
    "        This uses two rules:\n",
    "        1. FormatCondition to ignore blank cells, and stop evaluating conditions if found\n",
    "        2. FormatCondition to apply the date-based highlighting\n",
    "        \n",
    "        The combination is required to get the effect of:\n",
    "        \"highlight if (due date <= today) AND (cell is not blank)\"\n",
    "        \n",
    "        The \"blank\" rule is executed first, and StopIfFound is set to true to prevent\n",
    "        the date rule from firing on blank (non-date) cells.\n",
    "        \"\"\"\n",
    "        \n",
    "        # date rule\n",
    "        date_cond = due.FormatConditions.Add(Type=xlc.xlCellValue, Operator=xlc.xlLessEqual, Formula1=\"=TODAY()\")\n",
    "        date_cond.StopIfTrue = False\n",
    "        date_cond.SetFirstPriority()  # don't worry, see blank_cond\n",
    "        font = date_cond.Font; interior = date_cond.Interior\n",
    "        \n",
    "        font.Color = -16383844\n",
    "        font.TintAndShade = 0\n",
    "        \n",
    "        interior.PatternColorIndex = xlc.xlAutomatic\n",
    "        interior.Color = 13551615\n",
    "        interior.TintAndShade = 0\n",
    "        \n",
    "        # blank rule\n",
    "        # Column letter is required for the \"blank\" formula:\n",
    "        # this is the formula recorded by macro, unknown if a relative\n",
    "        # or similar reference can be obtained in a less hacky way\n",
    "        \n",
    "        addr1 = due.Cells(1,1).GetAddress(False, False)\n",
    "        blank_cond = due.FormatConditions.Add(Type=xlc.xlExpression, Formula1=f\"=LEN(TRIM({addr1}))=0\")\n",
    "        blank_cond.SetFirstPriority()  # :)\n",
    "        blank_cond.StopIfTrue = True\n",
    "        \n",
    "        # no format set\n",
    "            \n",
    "    def _force_nowrap(self, col):\n",
    "        col.ColumnWidth = 255\n",
    "        col.AutoFit()\n",
    "        \n",
    "def _dfs_visit(g, parent, visit, depth):\n",
    "    for node in sorted(g.successors(parent)):\n",
    "        visit(node, depth)\n",
    "        _dfs_visit(g, node, visit, depth + 1)\n",
    "    \n",
    "def dfs_visit(g, visit):\n",
    "    roots = [n for n, idg in g.in_degree() if idg == 0]\n",
    "    for r in sorted(roots):\n",
    "        visit(r, 0)\n",
    "        _dfs_visit(g, r, visit, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save(wb, *a,**k):\n",
    "    wb.Application.DisplayAlerts = False\n",
    "    try:\n",
    "        wb.SaveAs(*a,**k)\n",
    "    finally:\n",
    "        wb.Application.DisplayAlerts = True\n",
    "    \n",
    "def sharepoint_path():\n",
    "    return \"https://pbsbiotech.sharepoint.com/sites/SoftwareEngineeringLV1/Shared Documents/Project Management/Software Active Development.xlsx\"\n",
    "    \n",
    "def save_to_sharepoint(wb):\n",
    "    fp = sharepoint_path()\n",
    "    Save(wb, fp, CreateBackup=False)\n",
    "    \n",
    "def checkout(wb):\n",
    "    # The check in/out process is REALLY\n",
    "    # kludgy from VBA. Check out essentially never\n",
    "    # works without waiting a short period of time\n",
    "    # for ... something ... to connect.\n",
    "    \n",
    "    # Regardless, we can reliably\n",
    "    # perform checkout by looping until it works.\n",
    "    \n",
    "    # 5 second timeout to be safe. \n",
    "    \n",
    "    xl = wb.Application\n",
    "    end = time.time() + 5  # 5 second timeout\n",
    "    while True:\n",
    "        try:\n",
    "            xl.Workbooks.CheckOut(wb.FullName)\n",
    "        except Exception:\n",
    "            if time.time() > end:\n",
    "                raise\n",
    "            time.sleep(0.2)  # give it a chance to think\n",
    "        else:\n",
    "            return\n",
    "    \n",
    "def publish(wb):\n",
    "    checkout(wb)\n",
    "    wb.CheckInWithVersion(True, \"\", True, xlc.xlCheckInMajorVersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_graph():\n",
    "    key = \"7676add9cac6631410403671cdd7850311987898\"\n",
    "    client = Client(\"issue.pbsbiotech.com\",key)\n",
    "    ad_issues = client.Issues.filter(status_id=\"*\")\n",
    "    ad_map = {i.id:i for i in ad_issues}\n",
    "\n",
    "    # first graph - all issues\n",
    "    g = nx.DiGraph()\n",
    "    for i in ad_issues:\n",
    "        iid = i.id\n",
    "        g.add_node(iid)\n",
    "        pid = i.parent\n",
    "        if pid is not None:\n",
    "            g.add_edge(pid, iid)\n",
    "\n",
    "    if not nx.is_forest(g):  # should not be possible\n",
    "        raise ValueError(\"Circles in graph :(\") \n",
    "    \n",
    "    # simple DFS impl for (parent, node) pair callbacks\n",
    "    def _dfs_visit2(g, parent, visit, depth):\n",
    "        for node in sorted(g.successors(parent)):\n",
    "            visit(parent, node)\n",
    "            _dfs_visit2(g, node, visit, depth + 1)\n",
    "        \n",
    "    def dfs_visit2(g, node, visit):\n",
    "        visit(None, node)\n",
    "        _dfs_visit2(g, node, visit, 1)\n",
    "    \n",
    "    def visit(parent, node):\n",
    "        g2.add_node(node)\n",
    "        if parent is not None:\n",
    "            g2.add_edge(parent, node)\n",
    "    \n",
    "    # second graph - only what we care about\n",
    "    # this routine loads all Active Development issues as well\n",
    "    # as any children, regardless of milestone\n",
    "    \n",
    "    fv_active = 96  # sprint/milestone ID for software Active Development\n",
    "    g2 = nx.DiGraph()\n",
    "    for i in ad_issues:\n",
    "        if i.fixed_version is None or i.fixed_version.id != fv_active:\n",
    "            continue\n",
    "        dfs_visit2(g, i.id, visit)\n",
    "\n",
    "    def show_tree(node, depth):\n",
    "        print(\" \"*depth + str(node))           \n",
    "    # dfs_visit(g, show_tree)\n",
    "    return g2, ad_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_constants():\n",
    "    try:\n",
    "        xlc.xlNormal\n",
    "        xlc.xlSolid\n",
    "        xlc.xlAutomatic\n",
    "        xlc.xlNone\n",
    "    except AttributeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def _get_xl_app():\n",
    "    return win32com.client.DispatchEx(\"Excel.Application\")\n",
    "\n",
    "def background_excel():\n",
    "\n",
    "    # It is possible (seems to happen after system updates) for\n",
    "    # the win32com.client.constants dictionary to fail to populate,\n",
    "    # due to some cache (perhaps the AppData/local/Temp folder?)\n",
    "    # being cleared. \n",
    "\n",
    "    # Because the DispatchEx method is fully dynamic,\n",
    "    # the constants dict isn't populated and all constant values must be\n",
    "    # known from other sources. By default, the xlc constants\n",
    "    # object uses win32com.client.constants, populated when\n",
    "    # gencache.EnsureDispatch is used. \n",
    "\n",
    "    # test a few of the constants here - if they work, go ahead. Otherwise,\n",
    "    # use the gencache method to try to force win32com to build the dicts.\n",
    "    # This method has drawbacks so issue a warning to user. \n",
    "    \n",
    "    # Test Protocol:\n",
    "    # 1. Delete ~/AppData/Local/Temp/gen_py/<python version>\n",
    "    # 2. Comment-out any code to save the workbook\n",
    "    # 3. Restart the notebook & run all cells\n",
    "    # 4. Verify it all works\n",
    "    # 5. Close excel & verify no longering excel process\n",
    "    # \n",
    "    # Run with and without a workbook opened by user\n",
    "    \n",
    "    # Tested 6/3/2020 - seems to work just fine\n",
    "    \n",
    "    xl = _get_xl_app()\n",
    "    if not _check_constants():\n",
    "        print(\"Warning: Excel constants dictionary not initialized. Attempting workaround...\")\n",
    "        \n",
    "        # Attempt to populate the dicts using gencache\n",
    "        xl2 = win32com.client.gencache.EnsureDispatch(\"Excel.Application\")\n",
    "        \n",
    "        # We don't want the Excel process to linger, but we also want to\n",
    "        # try to avoid nuking user's excel process if they're using it already.\n",
    "        if xl2.Workbooks.Count == 0:\n",
    "            xl2.Quit()\n",
    "        \n",
    "        del xl2\n",
    "        gc.collect()\n",
    "        \n",
    "        # try again, bail if fail\n",
    "        if not _check_constants():\n",
    "            raise RunTimeError(\"Failed to load win32com.client.constants dictionary\")\n",
    "        \n",
    "        print(\"Workaround successful. Resuming activity...\")\n",
    "        \n",
    "    return xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading issues and making graph...\n",
      "Opening background Excel task...\n",
      "Creating worksheet...\n",
      "Saving to sharepoint...\n",
      "Success! Wrapping up...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# issue fetch routine now uses superget(), which essentially eliminates the network bottleneck\n",
    "\n",
    "# remaining bottleneck is now the Visitor design, which performs all data entry and formatting\n",
    "# on a per-row basis, except for some formatting done in the finish() method. \n",
    "\n",
    "# next improvement would be to minimize the number of COM calls by deferring the actual \n",
    "# submission of data and formatting until the whole graph is parsed, and then using\n",
    "# bulk methods (e.g. Application.Union) to aggressively minimize the number of COM calls\n",
    "\n",
    "print(\"Downloading issues and making graph...\")\n",
    "g, ad_map = make_graph()\n",
    "\n",
    "template_path = os.path.expanduser(\"~\\\\documents\\\\pbs\\\\wip procedures-reports\\\\project task template2.xlsx\")\n",
    "\n",
    "print(\"Opening background Excel task...\")\n",
    "\n",
    "xl = background_excel()\n",
    "with HiddenXl(xl):\n",
    "    wb = xl.Workbooks.Open(template_path)\n",
    "    ws = wb.Worksheets(\"Outline\")\n",
    "\n",
    "    print(\"Creating worksheet...\")\n",
    "    visitor = PlanInitVisitor(ws, g, ad_map)\n",
    "    with screen_lock(xl):\n",
    "        visitor.visit_all()\n",
    "        visitor.finish()\n",
    "\n",
    "    print(\"Saving to sharepoint...\")\n",
    "    #save_to_sw_eng(wb)\n",
    "    #save_to_sharepoint(wb)\n",
    "    \n",
    "# increments major version\n",
    "#if 0: publish(wb)\n",
    "\n",
    "print(\"Success! Wrapping up...\")\n",
    "xl.ActiveWindow.WindowState = xlc.xlNormal\n",
    "\n",
    "# release & clean up COM object references\n",
    "del visitor, xl, wb, ws\n",
    "gc.collect()\n",
    "gc.collect()  # just in case :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
