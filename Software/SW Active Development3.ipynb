{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,urllib,json, logging, dateutil, queue, threading, networkx as nx, asyncio, aiohttp, gc, datetime\n",
    "from officelib.xllib import *\n",
    "from pywintypes import com_error\n",
    "import time\n",
    "\n",
    "_urljoin = urllib.parse.urljoin\n",
    "_urlencode = urllib.parse.urlencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConverterError(Exception):\n",
    "    pass\n",
    "\n",
    "class _RedmineConverter():\n",
    "    def __init__(self):\n",
    "        self._converters = {}\n",
    "        \n",
    "    def Register(self, kls):\n",
    "        self._converters[kls] = dict(kls._converter_table)\n",
    "        return kls  # allow function use as decorator\n",
    "        \n",
    "    def Deserialize(self, jobj, kls):\n",
    "        try:\n",
    "            tbl = self._converters[kls]\n",
    "        except KeyError:\n",
    "            raise\n",
    "        \n",
    "        obj = kls()\n",
    "        for key, val in jobj.items():\n",
    "            conv = tbl.get(key)\n",
    "            if conv:\n",
    "                if conv in self._converters:\n",
    "                    val = self.Deserialize(val, conv)\n",
    "                else:\n",
    "                    val = conv(val)\n",
    "            else:\n",
    "                pass\n",
    "                # pass : use val as-is (string)\n",
    "            setattr(obj, key, val)\n",
    "            \n",
    "        for key in tbl.keys():\n",
    "            if key not in jobj:\n",
    "                setattr(obj, key, None)\n",
    "        return obj\n",
    "            \n",
    "RedmineConverter = _RedmineConverter()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RedmineConverter.Register\n",
    "class Resource():\n",
    "    _converter_table = [\n",
    "        (\"name\", str),\n",
    "        (\"id\", int),\n",
    "        (\"value\", str)\n",
    "    ]\n",
    "    def __str__(self):\n",
    "        return f\"<{self.__class__.__name__} {self.name}, id={self.id}, v={repr(self.value)}>\"\n",
    "    __repr__ = __str__\n",
    "    \n",
    "    \n",
    "@RedmineConverter.Register\n",
    "class User():\n",
    "    _converter_table = [\n",
    "        (\"name\", str),\n",
    "        (\"id\", int)\n",
    "    ]\n",
    "    def __str__(self):\n",
    "        return f\"<{self.__class__.__name__} {self.name}, id={self.id}>\"\n",
    "    __repr__ = __str__\n",
    "    \n",
    "\n",
    "def Datetime(d):\n",
    "    return dateutil.parser.parse(d)\n",
    "\n",
    "\n",
    "def CustomFields(cf):\n",
    "    fields = {}\n",
    "    for f in cf:\n",
    "        fields[f['name']] = RedmineConverter.Deserialize(f, Resource)\n",
    "    return fields\n",
    "\n",
    "def Parent(p):\n",
    "    return p['id']\n",
    "\n",
    "@RedmineConverter.Register\n",
    "class Issue():\n",
    "    \n",
    "    _converter_table = [\n",
    "        (\"author\", User),\n",
    "        (\"custom_fields\", CustomFields),\n",
    "        (\"fixed_version\", Resource),\n",
    "        (\"status\", Resource),\n",
    "        (\"created_on\", Datetime),\n",
    "        (\"updated_on\", Datetime),\n",
    "        (\"id\", int),\n",
    "        (\"project\", Resource),\n",
    "        (\"priority\", Resource),\n",
    "        (\"due_date\", Datetime),\n",
    "        (\"tracker\", Resource),\n",
    "        (\"parent\", Parent),\n",
    "        (\"closed_on\", Datetime),\n",
    "        (\"start_date\", Datetime),\n",
    "        (\"assigned_to\", User),\n",
    "        (\"estimated_hours\", float)\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<{self.__class__.__name__}: '{self.subject}'>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client():\n",
    "    def __init__(self, url, key):\n",
    "        if not url.startswith(\"http\"):\n",
    "            url = \"https://\"+url\n",
    "        self._url = url\n",
    "        self._key = key\n",
    "        self._sess = requests.Session()\n",
    "        self._headers = {'X-Redmine-API-Key': self._key}\n",
    "        self._Issues = None\n",
    "        \n",
    "    def _rawget(self, url, headers):\n",
    "        r = self._sess.get(url, headers=headers)\n",
    "        r.raise_for_status()\n",
    "        return r\n",
    "    \n",
    "    def _prep(self, path, opts):\n",
    "        base = _urljoin(self._url, path)\n",
    "        qs = _urlencode(opts)\n",
    "        url = f\"{base}?{qs}\"\n",
    "        return url, self._headers\n",
    "    \n",
    "    def get(self, path, opts):\n",
    "        url, headers = self._prep(path, opts)\n",
    "        return self._rawget(url, headers)\n",
    "    \n",
    "    async def get_async(self, path, opts):\n",
    "        url, headers = self._prep(path, opts)\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, headers=headers) as r:\n",
    "                r.raise_for_status()\n",
    "                return await r.json()\n",
    "    \n",
    "    def _get_iter_worker(self, obj_key, outq, path, opts=None):\n",
    "        offset = 0\n",
    "        limit = 100\n",
    "        limit = min(max(limit, 0), 100)\n",
    "        total_count = 0\n",
    "        \n",
    "        opts = opts or {}\n",
    "        while True:\n",
    "            opts['limit'] = limit\n",
    "            opts['offset'] = offset\n",
    "            r = self.get(path, opts)\n",
    "            \n",
    "            j = r.json()\n",
    "            items = j[obj_key]\n",
    "            outq.put(items)\n",
    "            print(sorted(j.keys()))\n",
    "            print(j['total_count'])\n",
    "            total_count = int(j.get('total_count', 0))\n",
    "            offset += len(items)\n",
    "            if offset >= total_count:\n",
    "                break\n",
    "        outq.put(None)\n",
    "        \n",
    "    def _get_iter(self, obj_key, path, opts=None, q=None):\n",
    "        \"\"\" This is only threaded because an early prototype was threaded\n",
    "        and I was too lazy to fix the method.\n",
    "        \"\"\"\n",
    "        q = q or queue.Queue()\n",
    "        def work():\n",
    "            self._get_iter_worker(obj_key, q, path, opts)\n",
    "        worker = threading.Thread(None, target=work, daemon=True)\n",
    "        worker.start()\n",
    "        return q\n",
    "            \n",
    "    @property\n",
    "    def Issues(self):\n",
    "        if self._Issues is None:\n",
    "            self._Issues = IssuesClient(self)\n",
    "        return self._Issues\n",
    "    \n",
    "    def close(self):\n",
    "        self._Issues = None\n",
    "        \n",
    "class IssuesClient():\n",
    "    def __init__(self, client):\n",
    "        self._client = client\n",
    "        \n",
    "    def filter(self, /, **opts):\n",
    "        q = self._client._get_iter(\"issues\", \"/issues.json\", opts)\n",
    "        issues = []\n",
    "        D = RedmineConverter.Deserialize\n",
    "        while True:\n",
    "            chunk = q.get()\n",
    "            if chunk is None:  # end of objects\n",
    "                break\n",
    "            issues.extend(D(i,Issue) for i in chunk)\n",
    "        return issues\n",
    "    \n",
    "    def filter_with_children(self, /, include_closed=False, **opts):\n",
    "        \"\"\" \n",
    "        Gets all issues that pass the given filter, along with\n",
    "        all their children.\n",
    "        \n",
    "        Since the only way to get children is to download an issue\n",
    "        by itself, all issues in the initial filter end up double-\n",
    "        downloaded.\n",
    "        \n",
    "        This method is garbage but works fine for now\n",
    "        with the small number of active development issues. \n",
    "        \"\"\"\n",
    "        issues = self.filter(**opts)\n",
    "        \n",
    "        inq = queue.Queue()\n",
    "        outq = queue.Queue()\n",
    "        \n",
    "        opts.pop(\"limit\", None)\n",
    "        opts.pop(\"offset\", None)\n",
    "        opts['include'] = 'children'\n",
    "        \n",
    "        pool = AsyncioWorkerPool(self._client, opts)\n",
    "        seen = set()\n",
    "        pending = set()\n",
    "        n = 0\n",
    "        for i in issues:\n",
    "            pool.put(\"/issues/%d.json\"%i.id)\n",
    "            seen.add(i.id)\n",
    "            pending.add(i.id)\n",
    "            n += 1\n",
    "        \n",
    "        while n:\n",
    "            ob = pool.get()\n",
    "            n -= 1\n",
    "            i = RedmineConverter.Deserialize(ob, Issue)\n",
    "            \n",
    "            # downloading an issue with children includes closed issues,\n",
    "            # so we manually skip ading them by checking the closed_on \n",
    "            # value. \n",
    "            if (not include_closed) and i.closed_on is not None:\n",
    "                continue\n",
    "            if i.id not in seen:\n",
    "                issues.append(i)\n",
    "                seen.add(i.id)\n",
    "            for c in i.__dict__.get('children', []):\n",
    "                cid = c['id']\n",
    "                if cid not in pending:\n",
    "                    pool.put(\"/issues/%d.json\"%cid)\n",
    "                    pending.add(cid)\n",
    "                    n += 1\n",
    "        pool.close()\n",
    "        return issues\n",
    "    \n",
    "    \n",
    "class ThreadWorkerPool:\n",
    "    \"\"\"\n",
    "    Thread based worker pool. \n",
    "    Garbage because python threads are\n",
    "    garbate. Reference API for asyncio\n",
    "    worker pool. \n",
    "    \"\"\"\n",
    "    def __init__(self, client, opts):\n",
    "        self.client = client\n",
    "        self.opts = opts\n",
    "        self.inq = queue.Queue()\n",
    "        self.outq = queue.Queue()\n",
    "        self.workers = []\n",
    "        for _ in range(8):\n",
    "            w = threading.Thread(None, target=self.work, daemon=True)\n",
    "            w.start()\n",
    "            self.workers.append(w)\n",
    "            \n",
    "    def close(self):\n",
    "        for _ in self.workers:\n",
    "            self.inq.put(None)\n",
    "        \n",
    "    def put(self, u):\n",
    "        self.inq.put(u)\n",
    "        \n",
    "    def get(self):\n",
    "        return self.outq.get()\n",
    "        \n",
    "    def work(self):\n",
    "        while True:\n",
    "            u = self.inq.get()\n",
    "            if u is None:\n",
    "                break\n",
    "            r = self.client.get(u, self.opts)\n",
    "            obj = r.json()['issue']\n",
    "            self.outq.put(obj)\n",
    "\n",
    "            \n",
    "class AsyncioWorkerPool:\n",
    "    \"\"\" Garbage, spaghetti-based worker pool.\n",
    "    Works well enough for what I'm trying to do.\n",
    "    \"\"\"\n",
    "    def __init__(self, client, opts):\n",
    "        self.client = client\n",
    "        self.opts = opts\n",
    "        self.inq = queue.Queue()\n",
    "        self.outq = queue.Queue()\n",
    "        self._stop = False\n",
    "        self._thread = threading.Thread(None, target=self._run)\n",
    "        self._thread.start()\n",
    "        \n",
    "    def _run(self):\n",
    "        asyncio.run(self._main())\n",
    "    \n",
    "    async def _main(self):\n",
    "        loop = asyncio.get_running_loop()\n",
    "        self._workers = []\n",
    "        for _ in range(8):  # 8 worker \"threads\"\n",
    "            w = loop.create_task(self._work())\n",
    "            self._workers.append(w)\n",
    "            \n",
    "        # this feels really round-about. \n",
    "        # I assume I'm going it wrong?\n",
    "        self._fut = asyncio.gather(*self._workers)\n",
    "        await self._fut\n",
    "            \n",
    "    def close(self):\n",
    "        self._stop = True\n",
    "        for _ in self._workers:\n",
    "            self.inq.put(None)\n",
    "        self._thread.join()\n",
    "            \n",
    "    async def _work(self):\n",
    "        while not self._stop:\n",
    "            try:\n",
    "                u = self.inq.get_nowait()\n",
    "            except queue.Empty:\n",
    "                await asyncio.sleep(0.1)\n",
    "            else:\n",
    "                if u is None:\n",
    "                    break\n",
    "                j = await self.client.get_async(u, self.opts)\n",
    "                self.outq.put(j['issue'])\n",
    "        \n",
    "    def put(self, u):\n",
    "        self.inq.put(u)\n",
    "        \n",
    "    def get(self):\n",
    "        return self.outq.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Column:\n",
    "    def __init__(self, name, idx, header=None):\n",
    "        self.name = name\n",
    "        self.idx = idx\n",
    "        self.header = header or self.name\n",
    "        self.top = None\n",
    "        \n",
    "class ColumnConfig:\n",
    "    def __init__(self, cells, row=1):\n",
    "        self.cells = cells\n",
    "        self.cr = cells.Range\n",
    "        self.columns = {}\n",
    "        self._row = row\n",
    "        self._min = 0\n",
    "        self._max = 0\n",
    "        self._get_cache = {}\n",
    "        self._list = []\n",
    "        self._target_cache = {}\n",
    "        \n",
    "    def set_row(self, r):\n",
    "        self._row = r\n",
    "        \n",
    "    def add(self, name, idx, header=None):\n",
    "        if name in self.columns:\n",
    "            raise ValueError(name)\n",
    "        col = Column(name, idx, header)\n",
    "        self.columns[name] = col\n",
    "        self.columns[idx] = col\n",
    "        self._list.append(col)\n",
    "        col.top = self.cells(1, idx + 1)\n",
    "        \n",
    "        if idx < self._min:\n",
    "            self._min = idx\n",
    "        elif idx > self._max:\n",
    "            self._max = idx\n",
    "        \n",
    "    def get(self, v):\n",
    "        key = self._row, self.columns[v]\n",
    "        col = self._get_cache.get(key, None)\n",
    "        if col is None:\n",
    "            col = self.columns[v].top.GetOffset(self._row - 1, 0)\n",
    "            self._get_cache[key] = col\n",
    "        return col\n",
    "\n",
    "    def clear_cache(self):\n",
    "        self._get_cache.clear()\n",
    "        self._target_cache.clear()\n",
    "    \n",
    "    def target(self):\n",
    "        t = self._target_cache.get(self._row, None)\n",
    "        if t is None:\n",
    "            c1 = self.get(self._min)\n",
    "            c2 = self.get(self._max)\n",
    "            t = self.cr(c1, c2)\n",
    "            self._target_cache[self._row] = t\n",
    "        return t\n",
    "    \n",
    "    def apply_data(self, data):\n",
    "        target = self.target()\n",
    "        row = [None] * target.Columns.Count\n",
    "        for k, v in data.items():\n",
    "            col = self.columns[k]\n",
    "            row[col.idx - self._min] = v\n",
    "        target.Value2 = [row]\n",
    "           \n",
    "def resource_name(r):\n",
    "    if r is not None:\n",
    "        return r.name\n",
    "    return \"\"\n",
    "\n",
    "class PlanInitVisitor():\n",
    "    def __init__(self, ws, g, issues):\n",
    "        self.ws = ws\n",
    "        self.g = g\n",
    "        if not isinstance(issues, dict):\n",
    "            issues = {i.id:i for i in issues}\n",
    "        self.issues = issues\n",
    "        self.cells = ws.Cells\n",
    "        self.cr = self.cells.Range\n",
    "        self.nseen = 0\n",
    "        self.depth = 0\n",
    "        self.stack = [0]\n",
    "        \n",
    "        self.columns = ColumnConfig(self.cells, 3)\n",
    "        \n",
    "        spec = [\n",
    "            \"#\",\n",
    "            \"Issue\",\n",
    "            \"Name\",\n",
    "            \"Assignee(s)\",\n",
    "            \"% Done\",\n",
    "            \"Status\",\n",
    "            \"Hours\",\n",
    "            \"Priority\",\n",
    "            \"Last Update\",\n",
    "            \"Due Date\",\n",
    "            \"Weighted Score\",\n",
    "            \"Deliverable ID\",\n",
    "            \"Date1\",\n",
    "            \"Notes/Current Action(s)\",\n",
    "        ]\n",
    "        for i, s in enumerate(spec):\n",
    "            self.columns.add(s, i)\n",
    "        \n",
    "    def _indent(self):\n",
    "        self.depth += 1\n",
    "        self.stack.append(1)\n",
    "        \n",
    "    def _dedent(self, depth):\n",
    "        diff = self.depth - depth\n",
    "        self.depth = depth\n",
    "        for _ in range(diff):\n",
    "            self.stack.pop()\n",
    "        self.stack[-1] += 1\n",
    "        \n",
    "    def _increment(self):\n",
    "        self.stack[-1] += 1\n",
    "        \n",
    "    def _outline_number(self):\n",
    "        if len(self.stack) == 1:\n",
    "            return str(self.stack[0]) + \".0\"\n",
    "        return \".\".join(map(str,self.stack))\n",
    "    \n",
    "    def _get(self, node):\n",
    "        return self.issues[node]\n",
    "        \n",
    "    def _make_data(self, iss):\n",
    "        data = {\n",
    "            \"#\":                       self._outline_number(),\n",
    "            \"Issue\":                   iss.id,\n",
    "            \"Name\":                    iss.subject,\n",
    "            \"Assignee(s)\":             resource_name(iss.assigned_to),\n",
    "            \"% Done\":                  iss.done_ratio / 100,\n",
    "            \"Status\":                  resource_name(iss.status),\n",
    "            \"Hours\":                   iss.estimated_hours or 0,\n",
    "            \"Priority\":                resource_name(iss.priority),\n",
    "            \"Weighted Score\":          \"\",\n",
    "            \"Deliverable ID\":          \"\",\n",
    "            \"Date1\":                   \"\",\n",
    "            \"Notes/Current Action(s)\": \"\",\n",
    "            \"Due Date\":                iss.due_date,\n",
    "            \"Last Update\":             iss.updated_on\n",
    "         }\n",
    "        return data\n",
    "    \n",
    "    def _format_row(self):\n",
    "        get = self.columns.get\n",
    "        outline = get(\"#\")\n",
    "        iid = get(\"Issue\")\n",
    "        name = get(\"Name\")\n",
    "        assignee = get(\"Assignee(s)\")\n",
    "        done = get(\"% Done\")\n",
    "        status = get(\"Status\")\n",
    "        hours = get(\"Hours\")\n",
    "        due = get(\"Due Date\")\n",
    "        priority = get(\"Priority\")\n",
    "        updated = get(\"Last Update\")\n",
    "        target = self.columns.target()\n",
    "        \n",
    "        indent = len(self.stack) - 1\n",
    "        \n",
    "        # reset target range\n",
    "        target.Font.Bold = False\n",
    "        target.IndentLevel = 0\n",
    "        target.Font.Size = 10\n",
    "        if indent == 0:\n",
    "            self._fill(target, 'gray')\n",
    "        else:\n",
    "            self._fill(target, 'none')\n",
    "        \n",
    "        outline.Font.Bold = True\n",
    "        if indent == 0:  # major heading\n",
    "            name.Font.Bold = True \n",
    "            done.Font.Bold = True\n",
    "            status.Font.Bold = True\n",
    "        \n",
    "#         iid.NumberFormat = \"@\"\n",
    "#         outline.NumberFormat = \"@\"\n",
    "#         done.NumberFormat = \"0%\"\n",
    "#         hours.NumberFormat = \"0.0\"\n",
    "#         due.NumberFormat = \"m/d/yyyy\"\n",
    "#         updated.NumberFormat = \"m/d/yyyy h:mm\"\n",
    "        \n",
    "        outline.IndentLevel = indent\n",
    "        name.IndentLevel = indent\n",
    "        \n",
    "#         # center these cells\n",
    "#         for c in (done, status, hours, iid, priority):\n",
    "#             c.IndentLevel = 0\n",
    "#             c.HorizontalAlignment = xlc.xlCenter\n",
    "        \n",
    "    def _fill(self, cell, op):\n",
    "        # copied from vba macro\n",
    "        i = cell.Interior\n",
    "        if op == 'gray':\n",
    "            i.Pattern = xlc.xlSolid\n",
    "            i.PatternColorIndex = xlc.xlAutomatic\n",
    "            i.ThemeColor = xlc.xlThemeColorDark1\n",
    "            i.TintAndShade = -0.14996795556505\n",
    "            i.PatternTintAndShade = 0\n",
    "        elif op == 'none':\n",
    "            i.Pattern = xlc.xlNone\n",
    "            i.TintAndShade = 0\n",
    "            i.PatternTintAndShade = 0\n",
    "        else:\n",
    "            raise ValueError(op)\n",
    "        \n",
    "    def visit_all(self):\n",
    "        dfs_visit(self.g, self.visit)\n",
    "        \n",
    "    def visit(self, node, depth):\n",
    "        if depth > self.depth:\n",
    "            self._indent()\n",
    "        elif depth < self.depth:\n",
    "            self._dedent(depth)\n",
    "        else:\n",
    "            self._increment()\n",
    "        \n",
    "        iss = self._get(node)\n",
    "        data = self._make_data(iss)\n",
    "        \n",
    "        self._format_row()\n",
    "        self.columns.apply_data(data)\n",
    "        \n",
    "        outline = self.columns.get(\"#\")\n",
    "        iid = self.columns.get(\"Issue\")\n",
    "        \n",
    "        self._add_hyperlink(iid)\n",
    "        \n",
    "        # disable the \"number as text\" warning for the\n",
    "        # outline number and issue ID columns.\n",
    "        for c in (outline, iid):\n",
    "            try:\n",
    "                c.Errors.Item(xlc.xlNumberAsText).Ignore = True\n",
    "            except com_error:\n",
    "                # if there is no active error, the method throws an exception\n",
    "                pass \n",
    "        \n",
    "        self.nseen += 1\n",
    "        self.columns.set_row(self.nseen + 3)\n",
    "    \n",
    "    def _add_hyperlink(self, iid):\n",
    "        v = int(iid.Value2)\n",
    "        v = str(v)\n",
    "        href = \"https://issue.pbsbiotech.com/issues/\" + v\n",
    "        self.ws.Hyperlinks.Add(Anchor=iid, Address=href, TextToDisplay=v)\n",
    "        iid.Font.Underline = False\n",
    "    \n",
    "    def finish(self):\n",
    "        \n",
    "        # unpacking.....\n",
    "        get = self.columns.get\n",
    "        outline = get(\"#\").EntireColumn\n",
    "        iid = get(\"Issue\").EntireColumn\n",
    "        name = get(\"Name\").EntireColumn\n",
    "        assignee = get(\"Assignee(s)\").EntireColumn\n",
    "        done = get(\"% Done\").EntireColumn\n",
    "        status = get(\"Status\").EntireColumn\n",
    "        hours = get(\"Hours\").EntireColumn\n",
    "        due = get(\"Due Date\").EntireColumn\n",
    "        priority = get(\"Priority\").EntireColumn\n",
    "        updated = get(\"Last Update\").EntireColumn\n",
    "        \n",
    "        # set numbering formats\n",
    "        iid.NumberFormat = \"@\"\n",
    "        outline.NumberFormat = \"@\"\n",
    "        done.NumberFormat = \"0%\"\n",
    "        hours.NumberFormat = \"0.0\"\n",
    "        due.NumberFormat = \"m/d/yyyy\"\n",
    "        updated.NumberFormat = \"m/d - h:mm AM/PM\"\n",
    "        \n",
    "        # center these cells\n",
    "        for c in (done, status, hours, iid, priority, updated):\n",
    "            c.IndentLevel = 0\n",
    "            c.HorizontalAlignment = xlc.xlCenter\n",
    "            \n",
    "        # force all cells to not wrap...\n",
    "        for c in (outline, iid, name, assignee, done, status, hours, due,\n",
    "                 updated, priority):\n",
    "            self._force_nowrap(c)\n",
    "        \n",
    "        self._conditional_format_updated_recent(updated)\n",
    "        self._conditional_format_due_now(due)\n",
    "        \n",
    "                    \n",
    "        # Autofilter can be toggled before the no-wrap\n",
    "        # to account for dropdown arrow width, but\n",
    "        # this makes the cells wide. \n",
    "#         status.Cells(2,1).AutoFilter(1)\n",
    "        \n",
    "        self.columns.clear_cache()\n",
    "        \n",
    "    def _conditional_format_updated_recent(self, updated):\n",
    "        # based on macro recorded\n",
    "        # Conditional Formatting -> Highlight Cells Rules -> A Date Occurring -> Last 7 days\n",
    "        cond = updated.FormatConditions.Add(Type=xlc.xlTimePeriod, DateOperator=xlc.xlLast7Days)\n",
    "        cond.StopIfTrue = False\n",
    "        \n",
    "        # \"Green Fill with Dark Green Text\"\n",
    "        font = cond.Font; interior = cond.Interior\n",
    "        font.Color = -16752384\n",
    "        font.TintAndShade = 0\n",
    "        interior.PatternColorIndex = xlc.xlAutomatic\n",
    "        interior.Color = 13561798\n",
    "        interior.TintAndShade = 0\n",
    "        \n",
    "    def _conditional_format_due_now(self, due):\n",
    "        \"\"\"\n",
    "        Sets due date column to highlight tasks if they are \n",
    "        due on or earlier than the current date. \n",
    "        \n",
    "        This uses two rules:\n",
    "        1. FormatCondition to ignore blank cells, and stop evaluating conditions if found\n",
    "        2. FormatCondition to apply the date-based highlighting\n",
    "        \n",
    "        The combination is required to get the effect of:\n",
    "        \"highlight if (due date <= today) AND (cell is not blank)\"\n",
    "        \n",
    "        The \"blank\" rule is executed first, and StopIfFound is set to true to prevent\n",
    "        the date rule from firing on blank (non-date) cells.\n",
    "        \"\"\"\n",
    "        \n",
    "        # date rule\n",
    "        date_cond = due.FormatConditions.Add(Type=xlc.xlCellValue, Operator=xlc.xlLessEqual, Formula1=\"=TODAY()\")\n",
    "        date_cond.StopIfTrue = False\n",
    "        date_cond.SetFirstPriority()  # don't worry, see blank_cond\n",
    "        font = date_cond.Font; interior = date_cond.Interior\n",
    "        \n",
    "        font.Color = -16383844\n",
    "        font.TintAndShade = 0\n",
    "        \n",
    "        interior.PatternColorIndex = xlc.xlAutomatic\n",
    "        interior.Color = 13551615\n",
    "        interior.TintAndShade = 0\n",
    "        \n",
    "        # blank rule\n",
    "        # Column letter is required for the \"blank\" formula:\n",
    "        # this is the formula recorded by macro, unknown if a relative\n",
    "        # or similar reference can be obtained in a less hacky way\n",
    "        \n",
    "        addr1 = due.Cells(1,1).GetAddress(False, False)\n",
    "        blank_cond = due.FormatConditions.Add(Type=xlc.xlExpression, Formula1=f\"=LEN(TRIM({addr1}))=0\")\n",
    "        blank_cond.SetFirstPriority()  # :)\n",
    "        blank_cond.StopIfTrue = True\n",
    "        \n",
    "        # no format set\n",
    "            \n",
    "    def _force_nowrap(self, col):\n",
    "        col.ColumnWidth = 255\n",
    "        col.AutoFit()\n",
    "        \n",
    "def _dfs_visit(g, parent, visit, depth):\n",
    "    for node in sorted(g.successors(parent)):\n",
    "        visit(node, depth)\n",
    "        _dfs_visit(g, node, visit, depth + 1)\n",
    "    \n",
    "def dfs_visit(g, visit):\n",
    "    roots = [n for n, idg in g.in_degree() if idg == 0]\n",
    "    for r in sorted(roots):\n",
    "        visit(r, 0)\n",
    "        _dfs_visit(g, r, visit, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save(wb, *a,**k):\n",
    "    wb.Application.DisplayAlerts = False\n",
    "    try:\n",
    "        wb.SaveAs(*a,**k)\n",
    "    finally:\n",
    "        wb.Application.DisplayAlerts = True\n",
    "    \n",
    "def sharepoint_path():\n",
    "    return \"https://pbsbiotech.sharepoint.com/sites/SoftwareEngineeringLV1/Shared Documents/Project Management/Software Active Development.xlsx\"\n",
    "    \n",
    "def save_to_sharepoint(wb):\n",
    "    fp = sharepoint_path()\n",
    "    Save(wb, fp, CreateBackup=False)\n",
    "    \n",
    "def checkout(wb):\n",
    "    # The check in/out process is REALLY\n",
    "    # kludgy from VBA. Check out essentially never\n",
    "    # works without waiting a short period of time\n",
    "    # for ... something ... to connect.\n",
    "    \n",
    "    # Regardless, we can reliably\n",
    "    # perform checkout by looping until it works.\n",
    "    \n",
    "    # 5 second timeout to be safe. \n",
    "    \n",
    "    xl = wb.Application\n",
    "    end = time.time() + 5  # 5 second timeout\n",
    "    while True:\n",
    "        try:\n",
    "            xl.Workbooks.CheckOut(wb.FullName)\n",
    "        except Exception:\n",
    "            if time.time() > end:\n",
    "                raise\n",
    "            time.sleep(0.2)  # give it a chance to think\n",
    "        else:\n",
    "            return\n",
    "    \n",
    "def publish(wb):\n",
    "    checkout(wb)\n",
    "    wb.CheckInWithVersion(True, \"\", True, xlc.xlCheckInMajorVersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# It would be a lot easier code-wise to just download the entire issuetracker \n",
    "# and pluck out the relevant roots rather than using the current `filter_with_children` to \n",
    "# double download every single issue to build the hierarchy. \n",
    "# This would also require an order-of-magnitude less calls :)\n",
    "\n",
    "def make_graph():\n",
    "    key = \"7676add9cac6631410403671cdd7850311987898\"\n",
    "    client = Client(\"issue.pbsbiotech.com\",key)\n",
    "    ad_issues = client.Issues.filter_with_children(True, fixed_version_id=96)\n",
    "    ad_map = {i.id:i for i in ad_issues}\n",
    "\n",
    "    g = nx.DiGraph()\n",
    "    for i in ad_issues:\n",
    "        iid = i.id\n",
    "        g.add_node(iid)\n",
    "        pid = i.parent\n",
    "        if pid is not None:\n",
    "            g.add_edge(pid, iid)\n",
    "\n",
    "    if not nx.is_forest(g):  # should not be possible\n",
    "        raise ValueError(\"Circles in graph :(\") \n",
    "\n",
    "    def show_tree(node, depth):\n",
    "        print(\" \"*depth + str(node))           \n",
    "    # dfs_visit(g, show_tree)\n",
    "    return g, ad_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_constants():\n",
    "    try:\n",
    "        xlc.xlNormal\n",
    "        xlc.xlSolid\n",
    "        xlc.xlAutomatic\n",
    "        xlc.xlNone\n",
    "    except AttributeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def _get_xl_app():\n",
    "    return win32com.client.DispatchEx(\"Excel.Application\")\n",
    "\n",
    "def background_excel():\n",
    "\n",
    "    # It is possible (seems to happen after system updates) for\n",
    "    # the win32com.client.constants dictionary to fail to populate,\n",
    "    # due to some cache (perhaps the AppData/local/Temp folder?)\n",
    "    # being cleared. \n",
    "\n",
    "    # Because the DispatchEx method is fully dynamic,\n",
    "    # the constants dict isn't populated and all constant values must be\n",
    "    # known from other sources. By default, the xlc constants\n",
    "    # object uses win32com.client.constants, populated when\n",
    "    # gencache.EnsureDispatch is used. \n",
    "\n",
    "    # test a few of the constants here - if they work, go ahead. Otherwise,\n",
    "    # use the gencache method to try to force win32com to build the dicts.\n",
    "    # This method has drawbacks so issue a warning to user. \n",
    "    \n",
    "    # Test Protocol:\n",
    "    # 1. Delete ~/AppData/Local/Temp/gen_py/<python version>\n",
    "    # 2. Comment-out any code to save the workbook\n",
    "    # 3. Restart the notebook & run all cells\n",
    "    # 4. Verify it all works\n",
    "    # 5. Close excel & verify no longering excel process\n",
    "    # \n",
    "    # Run with and without a workbook opened by user\n",
    "    \n",
    "    # Tested 6/3/2020 - seems to work just fine\n",
    "    \n",
    "    xl = _get_xl_app()\n",
    "    if not _check_constants():\n",
    "        print(\"Warning: Excel constants dictionary not initialized. Attempting workaround...\")\n",
    "        \n",
    "        # Attempt to populate the dicts using gencache\n",
    "        xl2 = win32com.client.gencache.EnsureDispatch(\"Excel.Application\")\n",
    "        \n",
    "        # We don't want the Excel process to linger, but we also want to\n",
    "        # try to avoid nuking user's excel process if they're using it already.\n",
    "        if xl2.Workbooks.Count == 0:\n",
    "            xl2.Quit()\n",
    "        \n",
    "        del xl2\n",
    "        gc.collect()\n",
    "        \n",
    "        # try again, bail if fail\n",
    "        if not _check_constants():\n",
    "            raise RunTimeError(\"Failed to load win32com.client.constants dictionary\")\n",
    "        \n",
    "        print(\"Workaround successful. Resuming activity...\")\n",
    "        \n",
    "    return xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading issues and making graph...\n",
      "Opening background Excel task...\n",
      "Creating worksheet...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "5199",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-330167988a87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mvisitor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPlanInitVisitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mad_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mscreen_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mvisitor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisit_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mvisitor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-3a3212e73962>\u001b[0m in \u001b[0;36mvisit_all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvisit_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mdfs_visit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvisit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-3a3212e73962>\u001b[0m in \u001b[0;36mdfs_visit\u001b[1;34m(g, visit)\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[0mroots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_degree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0midg\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroots\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m         \u001b[0mvisit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[0m_dfs_visit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-3a3212e73962>\u001b[0m in \u001b[0;36mvisit\u001b[1;34m(self, node, depth)\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_increment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[0miss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-3a3212e73962>\u001b[0m in \u001b[0;36m_get\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 5199"
     ]
    }
   ],
   "source": [
    "print(\"Downloading issues and making graph...\")\n",
    "g, ad_map = make_graph()\n",
    "\n",
    "template_path = os.path.expanduser(\"~\\\\documents\\\\pbs\\\\wip procedures-reports\\\\project task template2.xlsx\")\n",
    "\n",
    "print(\"Opening background Excel task...\")\n",
    "\n",
    "xl = background_excel()\n",
    "with HiddenXl(xl):\n",
    "    wb = xl.Workbooks.Open(template_path)\n",
    "    ws = wb.Worksheets(\"Outline\")\n",
    "\n",
    "    print(\"Creating worksheet...\")\n",
    "    visitor = PlanInitVisitor(ws, g, ad_map)\n",
    "    with screen_lock(xl):\n",
    "        visitor.visit_all()\n",
    "        visitor.finish()\n",
    "\n",
    "    print(\"Saving to sharepoint...\")\n",
    "    #save_to_sw_eng(wb)\n",
    "    save_to_sharepoint(wb)\n",
    "    \n",
    "# increments major version\n",
    "#if 0: publish(wb)\n",
    "\n",
    "print(\"Success! Wrapping up...\")\n",
    "xl.ActiveWindow.WindowState = xlc.xlNormal\n",
    "\n",
    "# release & clean up COM object references\n",
    "del visitor, xl, wb, ws\n",
    "gc.collect()\n",
    "gc.collect()  # just in case :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4976,\n",
       " 5007,\n",
       " 5008,\n",
       " 5009,\n",
       " 5010,\n",
       " 5011,\n",
       " 5012,\n",
       " 5013,\n",
       " 5014,\n",
       " 5015,\n",
       " 5016,\n",
       " 5017,\n",
       " 5161,\n",
       " 5162,\n",
       " 5163,\n",
       " 5164,\n",
       " 5166,\n",
       " 5167,\n",
       " 5168,\n",
       " 5169,\n",
       " 5170,\n",
       " 5171,\n",
       " 5172,\n",
       " 5173,\n",
       " 5174,\n",
       " 5175,\n",
       " 5176,\n",
       " 5177,\n",
       " 5178,\n",
       " 5179,\n",
       " 5180,\n",
       " 5181,\n",
       " 5182,\n",
       " 5184,\n",
       " 5186,\n",
       " 5187,\n",
       " 5188,\n",
       " 5189,\n",
       " 5190,\n",
       " 5191,\n",
       " 5192,\n",
       " 5193,\n",
       " 5194,\n",
       " 5195,\n",
       " 5196,\n",
       " 5197,\n",
       " 5198,\n",
       " 5200,\n",
       " 5201,\n",
       " 5202,\n",
       " 5203,\n",
       " 5204,\n",
       " 5205,\n",
       " 5206,\n",
       " 5207,\n",
       " 5208,\n",
       " 5209,\n",
       " 5220,\n",
       " 5221,\n",
       " 5236,\n",
       " 5237,\n",
       " 5238,\n",
       " 5239,\n",
       " 5240,\n",
       " 5260,\n",
       " 5261,\n",
       " 5272,\n",
       " 5277]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ad_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
