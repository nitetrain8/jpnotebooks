{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, sys\n",
    "from datetime import date\n",
    "import importlib\n",
    "import jpnotebooks.Software.SDLC_traceability_tools.issuetracker_item_extracter2 as iie\n",
    "import jpnotebooks.Software.SDLC_traceability_tools.user_tests_parser as utp\n",
    "import scripts.tools.redmine_cache as rmc\n",
    "from scripts.software_frs import frs_traceability2 as FRS\n",
    "\n",
    "iie = importlib.reload(iie)\n",
    "utp = importlib.reload(utp)\n",
    "rmc = importlib.reload(rmc)\n",
    "\n",
    "UserTestsParser = utp.UserTestsParser\n",
    "RequirementExtracter = iie.RequirementExtracter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cache = None\n",
    "_age = None\n",
    "_client = None\n",
    "\n",
    "def _get_client():\n",
    "    global _client\n",
    "    if _client is None:\n",
    "        _client = rmc.RedmineClient()\n",
    "    return _client\n",
    "\n",
    "def _download_issues():\n",
    "    _client = _get_client()\n",
    "    return _client.get_filtered([('project.identifier', '==', 'pbssoftware')])\n",
    "\n",
    "def load_issues():\n",
    "    return _download_issues()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class WebFRSIssuetrackerParser(iie.IssuetrackerParser):\n",
    "    def __init__(self, types=(\"URS\", \"FRS\", \"SDS\", \"SWDS\")):\n",
    "        types = list(types) + [\"3.0WebFRS\"]\n",
    "        super().__init__(types)\n",
    "        \n",
    "    def _get_result_for_line(self, line):\n",
    "        \"\"\" identical to parent function, but checks the type after\n",
    "        scanning the line to return only 3.0WebFRS items, converted\n",
    "        to plain FRS items. \n",
    "        \"\"\"\n",
    "        if not line or line.isspace():\n",
    "            return self._EMPTY_LINE, None, None, None, True\n",
    "\n",
    "        m = self._item_match(line)\n",
    "        if m is None: \n",
    "            return self._RAW_LINE, \"\", \"\", line.strip(), False\n",
    "        \n",
    "        dash1, typ, num, text, dash2 = m.groups()\n",
    "        if typ != '3.0WebFRS':\n",
    "            return self._EMPTY_LINE, None, None, None, True\n",
    "        else:\n",
    "            typ = 'FRS'\n",
    "            num = \"3.\" + num\n",
    "        cancel = dash1 == dash2 and dash1 != \"\"\n",
    "        return self._REQ_RESULT, typ, num, text, cancel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtags = [\n",
    "    \"URS\",\n",
    "    \"FRS\",\n",
    "    \"SWDS\",\n",
    "    \"CS\",\n",
    "    \"BUG\"\n",
    "]\n",
    "\n",
    "ttags = [\n",
    "    \"USR\"\n",
    "]\n",
    "\n",
    "_ignore = {3194, 3287}\n",
    "_sprints = {\n",
    "    'Legacy',\n",
    "    '3.0',\n",
    "    '3.0.1',\n",
    "    '3.0.2',\n",
    "    '3.0.3',\n",
    "    '3.0.4',\n",
    "    '3.0.5',\n",
    "    '3.0.6',\n",
    "    '3.0.7'\n",
    "}\n",
    "\n",
    "def relevant(i):\n",
    "    return i.sprint_milestone.name in _sprints and i.id not in _ignore and i.status != \"Rejected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iie = importlib.reload(iie)\n",
    "utp = importlib.reload(utp)\n",
    "UserTestsParser = utp.UserTestsParser\n",
    "RequirementExtracter = iie.RequirementExtracter\n",
    "\n",
    "force = True\n",
    "force = False\n",
    "issues = load_issues()\n",
    "issues2 = list(filter(relevant, issues.values()))\n",
    "parser = iie.IssuetrackerParser(rtags)\n",
    "reqs = parser.parse_all(issues2)\n",
    "\n",
    "parser2 = UserTestsParser()\n",
    "tests = parser2.parse_excel(\"C:\\\\Users\\\\Nathan\\\\Documents\\\\Dropbox\\\\FRS\\\\FRS Tests 190226.xlsx\")\n",
    "\n",
    "parser3 = WebFRSIssuetrackerParser(rtags)\n",
    "reqs2 = parser3.parse_all(issues2)\n",
    "\n",
    "allitems = reqs + tests + reqs2\n",
    "\n",
    "def missing_parents(req, ref, reqs):\n",
    "    if req.type == \"TEST\":\n",
    "        return 'ignore'\n",
    "    else:\n",
    "        return 'fix'\n",
    "\n",
    "rex = RequirementExtracter(rtags, ttags)\n",
    "rex.config.missing_parents = missing_parents\n",
    "rows = rex.extract(allitems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from officelib.xllib import *\n",
    "class JamesExcelFileRequirementsParser():\n",
    "    def __init__(self, rtags):\n",
    "        self.rtags = rtags\n",
    "    \n",
    "    def extract(self, fp):\n",
    "        xl = Excel()\n",
    "        with screen_lock(xl):\n",
    "            wb = xl.Workbooks.Open(fp)\n",
    "            ws = wb.Worksheets(\"specs list\")\n",
    "            reqs = self._extract(xl, wb, ws)\n",
    "            wb.Close(False)\n",
    "        return reqs\n",
    "    \n",
    "    def _extract(self, xl, wb, ws):\n",
    "        cells = ws.Cells\n",
    "        cr = cells.Range\n",
    "        c1 = cr(\"B1\")\n",
    "        c2 = c1.End(xlc.xlDown).GetOffset(0, 4)\n",
    "        data = cr(c1.GetOffset(1, 0), c2).Value2\n",
    "        return self._get_data(data)\n",
    "    \n",
    "    def _get_data(self, data):\n",
    "        out = []\n",
    "        for num, text, refs, uprefs, iss in data:\n",
    "            if num.startswith(\"<\"):\n",
    "                continue\n",
    "            refs = [s.strip() for s in (refs or \"\").replace(\",\", \"\").split()]\n",
    "            ref = iie.Reference(\"FRS\", num, False, refs)\n",
    "            out.append(ref)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "newitems = JamesExcelFileRequirementsParser(rtags).extract(\"C:\\\\Users\\\\Nathan\\\\Documents\\\\Personal\\\\test\\\\NewPumpFeatures.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "import itertools\n",
    "\n",
    "def impacted_nodes(G, node):\n",
    "    a = nx.shortest_path_length(G, target=node)\n",
    "    d = nx.shortest_path_length(G, source=node)\n",
    "    return {n for n in itertools.chain(a, d)}\n",
    "\n",
    "def impact_graph(G, node):\n",
    "    r = impacted_nodes(G, node)\n",
    "    return G.subgraph(r)\n",
    "\n",
    "def items_to_graph(items):\n",
    "    G = nx.DiGraph()\n",
    "    for req in items:\n",
    "        if not req.obs:\n",
    "            for ref in req.refs:\n",
    "                G.add_edge(ref, req.tag)\n",
    "    return G\n",
    "\n",
    "def dictify(items):\n",
    "    out = {}\n",
    "    for i in items:\n",
    "        if not i.obs:\n",
    "            if i.tag in out:\n",
    "                print(\"Warning: duplicate for tag: %s\"%i.tag)\n",
    "            out[i.tag] = i\n",
    "    return out\n",
    "\n",
    "def add_implicit_local_refs(items):\n",
    "    for req in items:\n",
    "        hpref = req.tag.rsplit(\".\", 1)[0]\n",
    "        if hpref != req.tag:\n",
    "            req.refs.add(hpref)\n",
    "            \n",
    "def make_impact_graph(G, node, file):\n",
    "    SG = impact_graph(G, node)\n",
    "    nx.write_graphml(G, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRS = importlib.reload(FRS)\n",
    "_imkey = re.compile(r\"(%s)(\\d+)\\.?([\\d\\.]*)\" % \"|\".join(['URS', 'FRS', 'SDS'])).match\n",
    "\n",
    "def key_match(key):\n",
    "    m = _imkey(key)\n",
    "    if m:\n",
    "        type, first, others = m.groups()\n",
    "        return type+first, others\n",
    "    return key, \"\"\n",
    "\n",
    "def root_for_type(items, typ):\n",
    "    root = FRS.Root(key_match)\n",
    "    for req in items:\n",
    "        if req.type == typ and not req.obs:\n",
    "            root.add(req.tag, 0)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URS3652.7 {'URS3652'}\n"
     ]
    }
   ],
   "source": [
    "add_implicit_local_refs(allitems)\n",
    "add_implicit_local_refs(newitems)\n",
    "urs = root_for_type(allitems, \"URS\")\n",
    "G = items_to_graph(allitems)\n",
    "reqs = dictify(allitems)\n",
    "\n",
    "with open(\"test.nnf\", 'w') as f:\n",
    "    for u in urs.iter():\n",
    "        if u.is_leaf():\n",
    "            desc = nx.shortest_path_length(G, source=u.id)\n",
    "            G2 = condensed_graph(desc, reqs)\n",
    "            f.write(\"topN SWDev xx Req:%s\\n\"%(u.id))\n",
    "            for a,b in G2.edges():\n",
    "                f.write(\"Req:%s %s xx %s\\n\"%(u.id, a, b))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reqs[\"URS3652.7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testitems = []\n",
    "def add(typ, num, refs=()):\n",
    "    testitems.append(iie.Reference(typ, num, False, refs))\n",
    "    \n",
    "add(\"URS\", \"4370\")\n",
    "add(\"URS\", \"4370.6\")\n",
    "add(\"URS\", \"4370.6.2\")\n",
    "add(\"FRS\", \"4401\")\n",
    "add(\"FRS\", \"4401.2\")\n",
    "add(\"FRS\", \"4401.2.3\", [\"URS4370.6.2\"])\n",
    "add(\"FRS\", \"2321\", [\"FRS4401.2.3\", \"URS4370.6.2\"])\n",
    "add(\"FRS\", \"2321.1\", [\"URS4370.6.2\"])\n",
    "add(\"FRS\", \"2321.2\", [\"URS4370.6.2\"])\n",
    "add(\"FRS\", \"2321.3\", [\"URS4370.6.2\"])\n",
    "add(\"FRS\", \"2321.4\", [\"URS4370.6.2\"])\n",
    "add(\"FRS\", \"2321.5\", [\"URS4370.6.2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_implicit_local_refs(allitems)\n",
    "G = items_to_graph(allitems)\n",
    "reqs = dictify(allitems)\n",
    "\n",
    "def condensed_graph(impacted, reqs):\n",
    "\n",
    "    # Impacted is a set of all nodes impacted, but has no edge data\n",
    "    # Edge data is contained in G\n",
    "\n",
    "    G2 = nx.DiGraph()\n",
    "\n",
    "    # \"fold\" references into horizontal hierarchy whereever \n",
    "    # a parent of the same requirement type has the same URS as \n",
    "    # its children\n",
    "\n",
    "    for node in impacted:\n",
    "        req = reqs[node]\n",
    "        hiparent = req.tag.rsplit(\".\", 1)[0]\n",
    "        if hiparent == req.tag or hiparent not in impacted:\n",
    "            # no parents to this req. just add refs\n",
    "            for ref in req.refs:\n",
    "                if ref not in impacted:\n",
    "                    continue\n",
    "                G2.add_edge(ref, req.tag)\n",
    "        else:\n",
    "            # maybe has refs to fold\n",
    "            parent = reqs[hiparent]\n",
    "            for ref in req.refs:\n",
    "                if ref not in impacted:\n",
    "                    continue\n",
    "                if ref in parent.refs:\n",
    "                    G2.add_edge(parent.tag, req.tag)\n",
    "                else:\n",
    "                    G2.add_edge(ref, req.tag)\n",
    "    return G2\n",
    "\n",
    "def condensed_impact_graph(G, epicenter, reqs):\n",
    "    impacted = impacted_nodes(G, epicenter)\n",
    "    # use a different color for epicenter\n",
    "    G.add_node(epicenter, color=\"yellow\")\n",
    "    return condensed_graph(impacted, reqs)\n",
    "    \n",
    "# G2 = condensed_impact_graph(G, \"FRS4401.2.3\")\n",
    "# nx.write_graphml(G2, \"test.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condensed_implement_graph(G, node, reqs):\n",
    "    d = nx.shortest_path_length(G, source=node)\n",
    "    return condensed_graph(d, reqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_implement_graph(G, nodes, reqs):\n",
    "    d = set()\n",
    "    for n in nodes:\n",
    "        try:\n",
    "            nrefs = impacted_nodes(G, n)\n",
    "        except nx.NodeNotFound:\n",
    "            pass\n",
    "        else:\n",
    "            d.update(nrefs)\n",
    "    print(d)\n",
    "    return condensed_graph(d, reqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"URS4370.6.2\"\n",
    "G2 = condensed_implement_graph(G, target, reqs)\n",
    "nx.write_graphml(G2, \"test.xml\")\n",
    "with open(\"colors.csv\", 'w') as f:\n",
    "    for node in G2.nodes():\n",
    "        if node == target:\n",
    "            color = \"yellow\"\n",
    "        else:\n",
    "            color=\"blue\"\n",
    "        f.write(\"%s,%s\\n\"%(node, color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: duplicate for tag: FRS3664.8.1\n",
      "Warning: duplicate for tag: FRS3664.8.1\n",
      "Warning: duplicate for tag: FRS4401.2.10.1\n",
      "Warning: duplicate for tag: FRS4401.2.10.2\n",
      "Warning: duplicate for tag: FRS4401.2.11.1\n",
      "Warning: duplicate for tag: FRS4401.2.12.2\n",
      "Warning: duplicate for tag: FRS4401.2.13.2\n",
      "Warning: duplicate for tag: FRS3664.4.9\n",
      "Warning: duplicate for tag: FRS3664.4.9.1\n",
      "Warning: duplicate for tag: FRS3664.4.9.2\n",
      "Warning: duplicate for tag: FRS3664.13\n",
      "Warning: duplicate for tag: FRS3664.13.1\n",
      "Warning: duplicate for tag: FRS3664.13.2\n",
      "Warning: duplicate for tag: FRS4370.1.3\n",
      "{'FRS4370.1.2', 'FRS4400.4.2', 'FRS4400.4.1', 'FRS3664.8.3', 'URS3664.1', 'FRS3664.4.9.1', 'URS3664.5', 'FRS4400.4.4.1', 'FRS4400.1.2.1', 'URS3664.3', 'FRS3664.4.8.1', 'FRS4401.2.13', 'FRS3664.13', 'FRS4370.1.1', 'FRS4400.3.2.1', 'FRS4401.2.13.2', 'FRS4400.4.4', 'FRS4401.2.15.1', 'FRS3664.12.2', 'FRS3664.7.5', 'FRS4400.1.1', 'FRS3664.8.1', 'FRS3664.7.6', 'FRS3664.4.9.2', 'FRS4400.3.4', 'FRS3664.13.2', 'FRS4400.2.3.1', 'FRS4401.2.15.2', 'FRS4400.2.1.1', 'FRS4400.2.1', 'FRS4400.1.4.1', 'FRS4400.3.1.1', 'FRS4400.1.4', 'FRS4400.3.3', 'FRS4401.2.12.1', 'FRS4370.1.2.2', 'FRS4401.2.11.2', 'URS4407.3', 'FRS3664.4.10.1', 'FRS4400.3.2', 'FRS4400.4.3.1', 'TEST2151', 'FRS3664.12.1', 'FRS4370.1.4', 'FRS4370.2.1', 'FRS4370.2.2', 'FRS4400.3.1', 'URS4370.11', 'FRS4401.2.11', 'FRS4370.1', 'FRS4400.1.1.1', 'FRS4400.2.3', 'FRS4400.1.3.1', 'FRS4401.2.12', 'FRS4370.1.3', 'URS4407', 'FRS4400.2.4', 'FRS4401.2.10.1', 'URS4370.12', 'FRS4370.2', 'URS3664.2', 'FRS3664.12', 'URS3664.6', 'FRS4400.2.2.1', 'FRS4401.2.14.1', 'FRS4401.2.11.1', 'FRS4401.2.11.3', 'FRS4370.1.2.1', 'FRS4401.2.13.1', 'FRS4400.1.3', 'FRS4401.2.13.3', 'FRS4400.2.2', 'FRS4400.2.4.1', 'FRS4400.4.1.1', 'FRS4401.2.14', 'FRS4401.2.10.2', 'FRS3664.13.1', 'FRS4401.2.12.2', 'FRS4401.2.14.3', 'FRS4401.2.12.3', 'FRS4370.1.5', 'FRS4400.1.2', 'FRS4401.2.14.2', 'FRS4400.3.4.1', 'FRS4400', 'FRS4400.4.2.1', 'FRS4400.4.3', 'FRS4401.2.10', 'URS3664', 'URS4407.1', 'URS3664.4', 'FRS4400.3.3.1', 'FRS4401.2.3.1', 'FRS3664.4.9'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'FRS4400.4.2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-18b4118636b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mreqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdictify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mG2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombined_implement_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_graphml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test.xml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-91c2b859dfc3>\u001b[0m in \u001b[0;36mcombined_implement_graph\u001b[1;34m(G, nodes, reqs)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrefs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcondensed_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-72-dc460970b139>\u001b[0m in \u001b[0;36mcondensed_graph\u001b[1;34m(impacted, reqs)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimpacted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mhiparent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhiparent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhiparent\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimpacted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'FRS4400.4.2'"
     ]
    }
   ],
   "source": [
    "\n",
    "new = {n.tag for n in newitems}\n",
    "\n",
    "for a in allitems:\n",
    "    if a.tag in new:\n",
    "        a.obs = True\n",
    "\n",
    "apn = allitems + newitems\n",
    "G = items_to_graph(apn)\n",
    "reqs = dictify(apn)\n",
    "\n",
    "G2 = combined_implement_graph(G, new, reqs)\n",
    "\n",
    "nx.write_graphml(G2, \"test.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FRS3664.12',\n",
       " 'FRS3664.12.1',\n",
       " 'FRS3664.12.2',\n",
       " 'FRS3664.13',\n",
       " 'FRS3664.13.1',\n",
       " 'FRS3664.13.2',\n",
       " 'FRS3664.4.10',\n",
       " 'FRS3664.4.10.1',\n",
       " 'FRS3664.4.8.1',\n",
       " 'FRS3664.4.9',\n",
       " 'FRS3664.4.9.1',\n",
       " 'FRS3664.4.9.2',\n",
       " 'FRS3664.7.5',\n",
       " 'FRS3664.7.6',\n",
       " 'FRS3664.8.1',\n",
       " 'FRS3664.8.3',\n",
       " 'FRS4370.1',\n",
       " 'FRS4370.1.1',\n",
       " 'FRS4370.1.2',\n",
       " 'FRS4370.1.2.1',\n",
       " 'FRS4370.1.2.2',\n",
       " 'FRS4370.1.3',\n",
       " 'FRS4370.1.4',\n",
       " 'FRS4370.1.5',\n",
       " 'FRS4370.2',\n",
       " 'FRS4370.2.1',\n",
       " 'FRS4370.2.2',\n",
       " 'FRS4401.2.10',\n",
       " 'FRS4401.2.10.1',\n",
       " 'FRS4401.2.10.2',\n",
       " 'FRS4401.2.11',\n",
       " 'FRS4401.2.11.1',\n",
       " 'FRS4401.2.11.2',\n",
       " 'FRS4401.2.11.3',\n",
       " 'FRS4401.2.12',\n",
       " 'FRS4401.2.12.1',\n",
       " 'FRS4401.2.12.2',\n",
       " 'FRS4401.2.12.3',\n",
       " 'FRS4401.2.13',\n",
       " 'FRS4401.2.13.1',\n",
       " 'FRS4401.2.13.2',\n",
       " 'FRS4401.2.13.3',\n",
       " 'FRS4401.2.14',\n",
       " 'FRS4401.2.14.1',\n",
       " 'FRS4401.2.14.2',\n",
       " 'FRS4401.2.14.3',\n",
       " 'FRS4401.2.15',\n",
       " 'FRS4401.2.15.1',\n",
       " 'FRS4401.2.15.2',\n",
       " 'FRS4401.2.3.1',\n",
       " 'FRSURS4370.11',\n",
       " 'FRSURS4370.12'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
